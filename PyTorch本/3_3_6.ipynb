{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch本3-3-6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbRY1E4pJex3+I2nJbSoTi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pea-sys/Til/blob/master/PyTorch%E6%9C%AC3_3_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONBu3ATfBhC4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 3.3～3.6 ネットワークモデルの作成\n",
        "本ファイルでは、PSPNetのネットワークモデルと順伝搬forward関数を作成します。\n",
        "\n",
        "\n",
        "# 3.3 学習目標\n",
        "* PSPNetのネットワーク構造をモジュール単位で理解する\n",
        "* PSPNetを構成する各モジュールの役割を理解する\n",
        "* PSPNetのネットワーククラスの実装を理解する\n",
        "\n",
        "# 3.4 学習目標\n",
        "* Featureモジュールのサブネットワーク構成を理解する\n",
        "* サブネットワークFeatureMap_convolution を実装できるようになる\n",
        "* Residual Blockを理解する\n",
        "* Dilated Convolutionを理解する\n",
        "* サブネットワークbottleNeckPSPとbottleNeckIdentifyPSPを実装できるようになる\n",
        "* Featureモジュールを実装できるようになる\n",
        "\n",
        "# 3.5 学習目標\n",
        "* Pyramid Poolingモジュールのサブネットワーク構成を理解する\n",
        "* Pyramid Poolingモジュールのマルチスケール処理の実現方法を理解する\n",
        "* Pyramid Poolingモジュールを実装できるようになる\n",
        "\n",
        "# 3.6 学習目標\n",
        "* Decoderモジュールのサブネットワーク構成を理解する\n",
        "* Decoder モジュールを実装できるようになる\n",
        "* AuxLossモジュールのサブネットワーク構成を理解する\n",
        "* AuxLossモジュールを実装できるようになる\n",
        "\n",
        "[写経元](https://github.com/YutaroOgawa/pytorch_advanced/blob/master/3_semantic_segmentation/3-3-6_NetworkModel.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYyFpLkP9N6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# パッケージのimport\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xyNP4RmC047",
        "colab_type": "text"
      },
      "source": [
        "# 3.3 PSPNetのネットワーク構造"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zS-TqskCytD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PSPNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(PSPNet, self).__init__()\n",
        "\n",
        "        # パラメータ設定\n",
        "        block_config = [3, 4, 6, 3]  # resnet50\n",
        "        img_size = 475\n",
        "        img_size_8 = 60  # img_sizeの1/8に\n",
        "\n",
        "        # 4つのモジュールを構成するサブネットワークの用意\n",
        "        self.feature_conv = FeatureMap_convolution()\n",
        "        self.feature_res_1 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
        "        self.feature_res_2 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
        "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
        "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
        "\n",
        "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[\n",
        "            6, 3, 2, 1], height=img_size_8, width=img_size_8)\n",
        "\n",
        "        self.decode_feature = DecodePSPFeature(\n",
        "            height=img_size, width=img_size, n_classes=n_classes)\n",
        "\n",
        "        self.aux = AuxiliaryPSPlayers(\n",
        "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_conv(x)\n",
        "        x = self.feature_res_1(x)\n",
        "        x = self.feature_res_2(x)\n",
        "        x = self.feature_dilated_res_1(x)\n",
        "\n",
        "        output_aux = self.aux(x)  # Featureモジュールの途中をAuxモジュールへ\n",
        "\n",
        "        x = self.feature_dilated_res_2(x)\n",
        "\n",
        "        x = self.pyramid_pooling(x)\n",
        "        output = self.decode_feature(x)\n",
        "\n",
        "        return (output, output_aux)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8JubxkZC696",
        "colab_type": "text"
      },
      "source": [
        "# 3.4 Featureモジュール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suDsKT8aC4eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class conv2DBatchNormRelu(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
        "        super(conv2DBatchNormRelu, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
        "                              kernel_size, stride, padding, dilation, bias=bias)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # inplase設定で入力を保存せずに出力を計算し、メモリ削減する\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.batchnorm(x)\n",
        "        outputs = self.relu(x)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNkz4Gr8DLEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeatureMap_convolution(nn.Module):\n",
        "    def __init__(self):\n",
        "        '''構成するネットワークを用意'''\n",
        "        super(FeatureMap_convolution, self).__init__()\n",
        "\n",
        "        # 畳み込み層1\n",
        "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n",
        "        self.cbnr_1 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
        "\n",
        "        # 畳み込み層2\n",
        "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n",
        "        self.cbnr_2 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
        "\n",
        "        # 畳み込み層3\n",
        "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n",
        "        self.cbnr_3 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
        "\n",
        "        # MaxPooling層\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cbnr_1(x)\n",
        "        x = self.cbnr_2(x)\n",
        "        x = self.cbnr_3(x)\n",
        "        outputs = self.maxpool(x)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlKNWFs1DNo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlockPSP(nn.Sequential):\n",
        "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
        "        super(ResidualBlockPSP, self).__init__()\n",
        "\n",
        "        # bottleNeckPSPの用意\n",
        "        self.add_module(\n",
        "            \"block1\",\n",
        "            bottleNeckPSP(in_channels, mid_channels,\n",
        "                          out_channels, stride, dilation)\n",
        "        )\n",
        "\n",
        "        # bottleNeckIdentifyPSPの繰り返しの用意\n",
        "        for i in range(n_blocks - 1):\n",
        "            self.add_module(\n",
        "                \"block\" + str(i+2),\n",
        "                bottleNeckIdentifyPSP(\n",
        "                    out_channels, mid_channels, stride, dilation)\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9Lz-4FLDPH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class conv2DBatchNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
        "        super(conv2DBatchNorm, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
        "                              kernel_size, stride, padding, dilation, bias=bias)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        outputs = self.batchnorm(x)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNAgh1DWDQoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bottleNeckPSP(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
        "        super(bottleNeckPSP, self).__init__()\n",
        "\n",
        "        self.cbr_1 = conv2DBatchNormRelu(\n",
        "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "        self.cbr_2 = conv2DBatchNormRelu(\n",
        "            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.cb_3 = conv2DBatchNorm(\n",
        "            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "\n",
        "        # スキップ結合\n",
        "        self.cb_residual = conv2DBatchNorm(\n",
        "            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
        "        residual = self.cb_residual(x)\n",
        "        return self.relu(conv + residual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lfCtrQEDSdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bottleNeckIdentifyPSP(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
        "        super(bottleNeckIdentifyPSP, self).__init__()\n",
        "\n",
        "        self.cbr_1 = conv2DBatchNormRelu(\n",
        "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "        self.cbr_2 = conv2DBatchNormRelu(\n",
        "            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.cb_3 = conv2DBatchNorm(\n",
        "            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
        "        residual = x\n",
        "        return self.relu(conv + residual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wif85iZaEDIT",
        "colab_type": "text"
      },
      "source": [
        "# 3.5 Pyramid Poolingモジュール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNeSNYb-DUOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PyramidPooling(nn.Module):\n",
        "    def __init__(self, in_channels, pool_sizes, height, width):\n",
        "        super(PyramidPooling, self).__init__()\n",
        "\n",
        "        # forwardで使用する画像サイズ\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "        # 各畳み込み層の出力チャネル数\n",
        "        out_channels = int(in_channels / len(pool_sizes))\n",
        "\n",
        "        # 各畳み込み層を作成\n",
        "        # この実装方法は愚直すぎてfor文で書きたいところですが、分かりやすさを優先しています\n",
        "        # pool_sizes: [6, 3, 2, 1]\n",
        "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
        "        self.cbr_1 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "\n",
        "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
        "        self.cbr_2 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "\n",
        "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
        "        self.cbr_3 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "\n",
        "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
        "        self.cbr_4 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out1 = self.cbr_1(self.avpool_1(x))\n",
        "        out1 = F.interpolate(out1, size=(\n",
        "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "        out2 = self.cbr_2(self.avpool_2(x))\n",
        "        out2 = F.interpolate(out2, size=(\n",
        "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "        out3 = self.cbr_3(self.avpool_3(x))\n",
        "        out3 = F.interpolate(out3, size=(\n",
        "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "        out4 = self.cbr_4(self.avpool_4(x))\n",
        "        out4 = F.interpolate(out4, size=(\n",
        "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "        # 最終的に結合させる、dim=1でチャネル数の次元で結合\n",
        "        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwUclinWEIxT",
        "colab_type": "text"
      },
      "source": [
        "# 3.6 Decoder、AuxLossモジュール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-l135N_EGgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecodePSPFeature(nn.Module):\n",
        "    def __init__(self, height, width, n_classes):\n",
        "        super(DecodePSPFeature, self).__init__()\n",
        "\n",
        "        # forwardで使用する画像サイズ\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "        self.cbr = conv2DBatchNormRelu(\n",
        "            in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
        "        self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.classification = nn.Conv2d(\n",
        "            in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cbr(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classification(x)\n",
        "        output = F.interpolate(\n",
        "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSx6zYjkEMAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AuxiliaryPSPlayers(nn.Module):\n",
        "    def __init__(self, in_channels, height, width, n_classes):\n",
        "        super(AuxiliaryPSPlayers, self).__init__()\n",
        "\n",
        "        # forwardで使用する画像サイズ\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "        self.cbr = conv2DBatchNormRelu(\n",
        "            in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
        "        self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.classification = nn.Conv2d(\n",
        "            in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cbr(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classification(x)\n",
        "        output = F.interpolate(\n",
        "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVcyv3HKEQfE",
        "colab_type": "text"
      },
      "source": [
        "# 動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_YOmnPzENtX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "842a4e51-46fc-4925-e04a-5ed9d2f0b9b5"
      },
      "source": [
        "\n",
        "# モデルの定義\n",
        "net = PSPNet(n_classes=21)\n",
        "net"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PSPNet(\n",
              "  (feature_conv): FeatureMap_convolution(\n",
              "    (cbnr_1): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (cbnr_2): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (cbnr_3): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (feature_res_1): ResidualBlockPSP(\n",
              "    (block1): bottleNeckPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (cb_residual): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block2): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block3): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (feature_res_2): ResidualBlockPSP(\n",
              "    (block1): bottleNeckPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (cb_residual): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block2): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block3): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block4): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (feature_dilated_res_1): ResidualBlockPSP(\n",
              "    (block1): bottleNeckPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (cb_residual): conv2DBatchNorm(\n",
              "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block2): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block3): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block4): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block5): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block6): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (feature_dilated_res_2): ResidualBlockPSP(\n",
              "    (block1): bottleNeckPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (cb_residual): conv2DBatchNorm(\n",
              "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block2): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block3): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pyramid_pooling): PyramidPooling(\n",
              "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
              "    (cbr_1): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
              "    (cbr_2): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
              "    (cbr_3): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
              "    (cbr_4): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (decode_feature): DecodePSPFeature(\n",
              "    (cbr): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (aux): AuxiliaryPSPlayers(\n",
              "    (cbr): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aiFxgmUESOv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75f9a42b-d71f-40ad-e391-0282da86b6b9"
      },
      "source": [
        "\n",
        "# ダミーデータの作成\n",
        "batch_size = 2\n",
        "dummy_img = torch.rand(batch_size, 3, 475, 475)\n",
        "\n",
        "# 計算\n",
        "outputs = net(dummy_img)\n",
        "print(outputs)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[[ 5.4332e-01,  5.2352e-01,  5.0372e-01,  ...,  1.4696e-01,\n",
            "            1.6725e-01,  1.8754e-01],\n",
            "          [ 5.3363e-01,  5.0842e-01,  4.8321e-01,  ...,  1.5220e-01,\n",
            "            1.7051e-01,  1.8881e-01],\n",
            "          [ 5.2395e-01,  4.9332e-01,  4.6270e-01,  ...,  1.5744e-01,\n",
            "            1.7376e-01,  1.9009e-01],\n",
            "          ...,\n",
            "          [ 1.8717e-01,  1.7092e-01,  1.5467e-01,  ...,  3.1289e-01,\n",
            "            3.4287e-01,  3.7286e-01],\n",
            "          [ 1.4064e-01,  1.2830e-01,  1.1597e-01,  ...,  3.4109e-01,\n",
            "            3.6964e-01,  3.9819e-01],\n",
            "          [ 9.4107e-02,  8.5688e-02,  7.7270e-02,  ...,  3.6929e-01,\n",
            "            3.9641e-01,  4.2352e-01]],\n",
            "\n",
            "         [[ 2.8615e-01,  3.4586e-01,  4.0556e-01,  ...,  6.2395e-01,\n",
            "            6.3153e-01,  6.3912e-01],\n",
            "          [ 3.1842e-01,  3.6826e-01,  4.1809e-01,  ...,  5.8165e-01,\n",
            "            5.8855e-01,  5.9546e-01],\n",
            "          [ 3.5070e-01,  3.9066e-01,  4.3062e-01,  ...,  5.3935e-01,\n",
            "            5.4557e-01,  5.5179e-01],\n",
            "          ...,\n",
            "          [ 1.0852e-01,  9.9012e-02,  8.9508e-02,  ...,  3.7864e-01,\n",
            "            4.3232e-01,  4.8600e-01],\n",
            "          [ 1.2518e-01,  1.1433e-01,  1.0348e-01,  ...,  3.9270e-01,\n",
            "            4.4907e-01,  5.0544e-01],\n",
            "          [ 1.4185e-01,  1.2965e-01,  1.1746e-01,  ...,  4.0677e-01,\n",
            "            4.6582e-01,  5.2487e-01]],\n",
            "\n",
            "         [[-2.6669e-01, -2.5259e-01, -2.3848e-01,  ...,  1.2616e-01,\n",
            "            1.2673e-01,  1.2730e-01],\n",
            "          [-2.7393e-01, -2.6809e-01, -2.6224e-01,  ...,  1.2728e-01,\n",
            "            1.3271e-01,  1.3814e-01],\n",
            "          [-2.8117e-01, -2.8359e-01, -2.8601e-01,  ...,  1.2839e-01,\n",
            "            1.3868e-01,  1.4897e-01],\n",
            "          ...,\n",
            "          [-2.7674e-01, -2.9268e-01, -3.0863e-01,  ..., -4.1341e-01,\n",
            "           -4.0395e-01, -3.9450e-01],\n",
            "          [-1.8239e-01, -2.0047e-01, -2.1856e-01,  ..., -3.9454e-01,\n",
            "           -3.9115e-01, -3.8775e-01],\n",
            "          [-8.8038e-02, -1.0827e-01, -1.2849e-01,  ..., -3.7568e-01,\n",
            "           -3.7834e-01, -3.8100e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8981e-01,  1.8187e-01,  1.7393e-01,  ...,  2.2512e-01,\n",
            "            2.1577e-01,  2.0643e-01],\n",
            "          [ 2.4444e-01,  2.2924e-01,  2.1404e-01,  ...,  2.4259e-01,\n",
            "            2.3095e-01,  2.1932e-01],\n",
            "          [ 2.9908e-01,  2.7661e-01,  2.5414e-01,  ...,  2.6006e-01,\n",
            "            2.4613e-01,  2.3221e-01],\n",
            "          ...,\n",
            "          [ 4.7552e-01,  5.0759e-01,  5.3966e-01,  ...,  4.7089e-01,\n",
            "            5.0504e-01,  5.3920e-01],\n",
            "          [ 5.1417e-01,  5.4534e-01,  5.7651e-01,  ...,  5.1877e-01,\n",
            "            5.5345e-01,  5.8813e-01],\n",
            "          [ 5.5282e-01,  5.8309e-01,  6.1335e-01,  ...,  5.6665e-01,\n",
            "            6.0185e-01,  6.3706e-01]],\n",
            "\n",
            "         [[ 7.6217e-01,  6.9746e-01,  6.3274e-01,  ...,  3.2431e-01,\n",
            "            2.6951e-01,  2.1471e-01],\n",
            "          [ 7.4320e-01,  6.8263e-01,  6.2206e-01,  ...,  3.5447e-01,\n",
            "            3.0758e-01,  2.6069e-01],\n",
            "          [ 7.2424e-01,  6.6781e-01,  6.1138e-01,  ...,  3.8463e-01,\n",
            "            3.4565e-01,  3.0667e-01],\n",
            "          ...,\n",
            "          [ 1.5253e-01,  1.2696e-01,  1.0139e-01,  ...,  3.1357e-01,\n",
            "            3.1402e-01,  3.1448e-01],\n",
            "          [ 1.6397e-01,  1.3570e-01,  1.0743e-01,  ...,  3.1131e-01,\n",
            "            2.9923e-01,  2.8714e-01],\n",
            "          [ 1.7540e-01,  1.4444e-01,  1.1348e-01,  ...,  3.0905e-01,\n",
            "            2.8443e-01,  2.5981e-01]],\n",
            "\n",
            "         [[ 5.1193e-01,  5.3591e-01,  5.5989e-01,  ...,  2.5956e-01,\n",
            "            2.3087e-01,  2.0218e-01],\n",
            "          [ 4.8948e-01,  5.1149e-01,  5.3351e-01,  ...,  2.0598e-01,\n",
            "            1.8334e-01,  1.6070e-01],\n",
            "          [ 4.6703e-01,  4.8708e-01,  5.0713e-01,  ...,  1.5240e-01,\n",
            "            1.3582e-01,  1.1923e-01],\n",
            "          ...,\n",
            "          [ 5.4199e-02,  2.6858e-02, -4.8364e-04,  ...,  1.8980e-03,\n",
            "            1.6305e-02,  3.0712e-02],\n",
            "          [ 2.6686e-02, -4.1169e-03, -3.4920e-02,  ..., -3.1819e-02,\n",
            "           -2.0162e-02, -8.5059e-03],\n",
            "          [-8.2785e-04, -3.5092e-02, -6.9355e-02,  ..., -6.5536e-02,\n",
            "           -5.6630e-02, -4.7724e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2406e-01,  2.1195e-01,  1.9985e-01,  ...,  2.1126e-01,\n",
            "            1.6758e-01,  1.2391e-01],\n",
            "          [ 2.0968e-01,  1.9591e-01,  1.8214e-01,  ...,  2.4399e-01,\n",
            "            2.0018e-01,  1.5636e-01],\n",
            "          [ 1.9530e-01,  1.7986e-01,  1.6443e-01,  ...,  2.7672e-01,\n",
            "            2.3277e-01,  1.8882e-01],\n",
            "          ...,\n",
            "          [ 5.2976e-01,  4.6458e-01,  3.9940e-01,  ...,  3.7307e-01,\n",
            "            3.6931e-01,  3.6555e-01],\n",
            "          [ 4.7424e-01,  4.1067e-01,  3.4709e-01,  ...,  3.9301e-01,\n",
            "            3.9265e-01,  3.9230e-01],\n",
            "          [ 4.1873e-01,  3.5676e-01,  2.9478e-01,  ...,  4.1294e-01,\n",
            "            4.1600e-01,  4.1905e-01]],\n",
            "\n",
            "         [[ 2.7790e-01,  4.0011e-01,  5.2232e-01,  ...,  6.6723e-01,\n",
            "            6.2993e-01,  5.9264e-01],\n",
            "          [ 2.8779e-01,  3.9588e-01,  5.0396e-01,  ...,  6.7436e-01,\n",
            "            6.4584e-01,  6.1732e-01],\n",
            "          [ 2.9769e-01,  3.9165e-01,  4.8561e-01,  ...,  6.8149e-01,\n",
            "            6.6174e-01,  6.4199e-01],\n",
            "          ...,\n",
            "          [ 2.3397e-01,  2.4332e-01,  2.5268e-01,  ...,  3.1932e-01,\n",
            "            2.9499e-01,  2.7067e-01],\n",
            "          [ 2.2472e-01,  2.2684e-01,  2.2897e-01,  ...,  3.1964e-01,\n",
            "            2.8630e-01,  2.5297e-01],\n",
            "          [ 2.1547e-01,  2.1036e-01,  2.0526e-01,  ...,  3.1996e-01,\n",
            "            2.7761e-01,  2.3527e-01]],\n",
            "\n",
            "         [[-3.3021e-01, -3.2270e-01, -3.1518e-01,  ..., -2.2998e-01,\n",
            "           -2.1971e-01, -2.0944e-01],\n",
            "          [-3.5067e-01, -3.4999e-01, -3.4931e-01,  ..., -2.6395e-01,\n",
            "           -2.5985e-01, -2.5576e-01],\n",
            "          [-3.7113e-01, -3.7729e-01, -3.8344e-01,  ..., -2.9792e-01,\n",
            "           -3.0000e-01, -3.0208e-01],\n",
            "          ...,\n",
            "          [-2.4252e-01, -2.4945e-01, -2.5638e-01,  ..., -4.5507e-01,\n",
            "           -4.9624e-01, -5.3742e-01],\n",
            "          [-2.5684e-01, -2.6113e-01, -2.6543e-01,  ..., -4.7243e-01,\n",
            "           -5.2580e-01, -5.7918e-01],\n",
            "          [-2.7116e-01, -2.7282e-01, -2.7447e-01,  ..., -4.8978e-01,\n",
            "           -5.5536e-01, -6.2094e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3950e-01,  1.9330e-01,  1.4711e-01,  ..., -2.6900e-01,\n",
            "           -2.4020e-01, -2.1139e-01],\n",
            "          [ 2.2034e-01,  1.7720e-01,  1.3405e-01,  ..., -2.1461e-01,\n",
            "           -1.8629e-01, -1.5797e-01],\n",
            "          [ 2.0119e-01,  1.6109e-01,  1.2099e-01,  ..., -1.6021e-01,\n",
            "           -1.3238e-01, -1.0456e-01],\n",
            "          ...,\n",
            "          [ 1.9259e-01,  1.5510e-01,  1.1761e-01,  ...,  3.8545e-01,\n",
            "            4.3643e-01,  4.8741e-01],\n",
            "          [ 2.5108e-01,  2.1570e-01,  1.8033e-01,  ...,  4.1343e-01,\n",
            "            4.5886e-01,  5.0429e-01],\n",
            "          [ 3.0957e-01,  2.7631e-01,  2.4304e-01,  ...,  4.4142e-01,\n",
            "            4.8129e-01,  5.2117e-01]],\n",
            "\n",
            "         [[ 6.7140e-01,  5.9634e-01,  5.2127e-01,  ..., -1.8487e-01,\n",
            "           -2.1174e-01, -2.3861e-01],\n",
            "          [ 6.3008e-01,  5.6375e-01,  4.9742e-01,  ..., -1.6195e-01,\n",
            "           -1.9509e-01, -2.2823e-01],\n",
            "          [ 5.8875e-01,  5.3115e-01,  4.7356e-01,  ..., -1.3904e-01,\n",
            "           -1.7844e-01, -2.1785e-01],\n",
            "          ...,\n",
            "          [-9.3249e-02, -1.3056e-01, -1.6787e-01,  ...,  6.3369e-02,\n",
            "            1.4698e-01,  2.3058e-01],\n",
            "          [-1.0150e-01, -1.3746e-01, -1.7342e-01,  ...,  5.9792e-02,\n",
            "            1.5338e-01,  2.4697e-01],\n",
            "          [-1.0974e-01, -1.4436e-01, -1.7897e-01,  ...,  5.6214e-02,\n",
            "            1.5979e-01,  2.6336e-01]],\n",
            "\n",
            "         [[ 5.0168e-01,  5.3364e-01,  5.6561e-01,  ...,  3.4071e-01,\n",
            "            3.9858e-01,  4.5644e-01],\n",
            "          [ 5.2239e-01,  5.4692e-01,  5.7146e-01,  ...,  2.7218e-01,\n",
            "            3.3499e-01,  3.9781e-01],\n",
            "          [ 5.4309e-01,  5.6020e-01,  5.7730e-01,  ...,  2.0365e-01,\n",
            "            2.7141e-01,  3.3918e-01],\n",
            "          ...,\n",
            "          [ 4.6778e-02,  5.0011e-02,  5.3244e-02,  ...,  1.3054e-01,\n",
            "            2.1801e-01,  3.0548e-01],\n",
            "          [ 5.0329e-02,  5.5463e-02,  6.0596e-02,  ...,  8.5600e-02,\n",
            "            1.7785e-01,  2.7010e-01],\n",
            "          [ 5.3880e-02,  6.0914e-02,  6.7948e-02,  ...,  4.0658e-02,\n",
            "            1.3769e-01,  2.3473e-01]]]], grad_fn=<UpsampleBilinear2DBackward>), tensor([[[[-4.9508e-01, -4.9340e-01, -4.9173e-01,  ..., -5.1096e-01,\n",
            "           -5.1181e-01, -5.1265e-01],\n",
            "          [-4.1267e-01, -4.1384e-01, -4.1500e-01,  ..., -4.6505e-01,\n",
            "           -4.6028e-01, -4.5550e-01],\n",
            "          [-3.3027e-01, -3.3427e-01, -3.3827e-01,  ..., -4.1913e-01,\n",
            "           -4.0874e-01, -3.9835e-01],\n",
            "          ...,\n",
            "          [-2.6402e-01, -2.6872e-01, -2.7342e-01,  ..., -1.0992e-01,\n",
            "           -1.6425e-01, -2.1859e-01],\n",
            "          [-2.9982e-01, -3.0056e-01, -3.0130e-01,  ..., -1.1445e-01,\n",
            "           -1.7484e-01, -2.3523e-01],\n",
            "          [-3.3563e-01, -3.3240e-01, -3.2918e-01,  ..., -1.1897e-01,\n",
            "           -1.8542e-01, -2.5188e-01]],\n",
            "\n",
            "         [[-5.5839e-01, -4.7357e-01, -3.8875e-01,  ...,  1.3709e-01,\n",
            "            1.7678e-01,  2.1647e-01],\n",
            "          [-4.8956e-01, -4.0850e-01, -3.2745e-01,  ...,  1.1914e-01,\n",
            "            1.5116e-01,  1.8318e-01],\n",
            "          [-4.2074e-01, -3.4344e-01, -2.6614e-01,  ...,  1.0118e-01,\n",
            "            1.2553e-01,  1.4989e-01],\n",
            "          ...,\n",
            "          [-3.6526e-01, -2.7731e-01, -1.8935e-01,  ..., -3.6317e-02,\n",
            "           -4.3724e-02, -5.1131e-02],\n",
            "          [-3.9333e-01, -3.0994e-01, -2.2655e-01,  ..., -2.3376e-02,\n",
            "           -2.8204e-02, -3.3032e-02],\n",
            "          [-4.2140e-01, -3.4257e-01, -2.6374e-01,  ..., -1.0436e-02,\n",
            "           -1.2684e-02, -1.4933e-02]],\n",
            "\n",
            "         [[-2.0085e-01, -1.9901e-01, -1.9718e-01,  ..., -3.1110e-01,\n",
            "           -2.8981e-01, -2.6851e-01],\n",
            "          [-1.5403e-01, -1.5344e-01, -1.5286e-01,  ..., -3.2085e-01,\n",
            "           -3.0242e-01, -2.8399e-01],\n",
            "          [-1.0720e-01, -1.0787e-01, -1.0854e-01,  ..., -3.3059e-01,\n",
            "           -3.1503e-01, -2.9947e-01],\n",
            "          ...,\n",
            "          [ 4.2196e-02,  5.7166e-02,  7.2136e-02,  ...,  2.4884e-01,\n",
            "            2.0802e-01,  1.6719e-01],\n",
            "          [ 2.7026e-02,  4.6736e-02,  6.6447e-02,  ...,  2.4952e-01,\n",
            "            2.0403e-01,  1.5853e-01],\n",
            "          [ 1.1856e-02,  3.6307e-02,  6.0758e-02,  ...,  2.5020e-01,\n",
            "            2.0003e-01,  1.4987e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9345e-01,  1.6273e-01,  1.3201e-01,  ..., -1.2543e-01,\n",
            "           -6.2915e-02, -4.0066e-04],\n",
            "          [ 1.8251e-01,  1.5348e-01,  1.2444e-01,  ..., -1.7869e-01,\n",
            "           -1.3317e-01, -8.7653e-02],\n",
            "          [ 1.7157e-01,  1.4423e-01,  1.1688e-01,  ..., -2.3194e-01,\n",
            "           -2.0342e-01, -1.7490e-01],\n",
            "          ...,\n",
            "          [ 1.7295e-01,  1.3469e-01,  9.6425e-02,  ...,  8.1240e-02,\n",
            "            8.1303e-02,  8.1367e-02],\n",
            "          [ 2.0604e-01,  1.5818e-01,  1.1032e-01,  ...,  7.6259e-02,\n",
            "            6.2863e-02,  4.9467e-02],\n",
            "          [ 2.3914e-01,  1.8168e-01,  1.2421e-01,  ...,  7.1279e-02,\n",
            "            4.4423e-02,  1.7568e-02]],\n",
            "\n",
            "         [[-5.0062e-01, -4.9402e-01, -4.8742e-01,  ..., -8.1271e-01,\n",
            "           -8.2894e-01, -8.4517e-01],\n",
            "          [-5.0625e-01, -4.9552e-01, -4.8479e-01,  ..., -7.7151e-01,\n",
            "           -7.9192e-01, -8.1233e-01],\n",
            "          [-5.1187e-01, -4.9702e-01, -4.8216e-01,  ..., -7.3032e-01,\n",
            "           -7.5491e-01, -7.7950e-01],\n",
            "          ...,\n",
            "          [-8.7391e-01, -8.5177e-01, -8.2963e-01,  ..., -6.9477e-01,\n",
            "           -7.1055e-01, -7.2633e-01],\n",
            "          [-9.5946e-01, -9.2734e-01, -8.9521e-01,  ..., -7.4496e-01,\n",
            "           -7.5898e-01, -7.7300e-01],\n",
            "          [-1.0450e+00, -1.0029e+00, -9.6078e-01,  ..., -7.9516e-01,\n",
            "           -8.0741e-01, -8.1967e-01]],\n",
            "\n",
            "         [[-4.2822e-01, -3.9427e-01, -3.6031e-01,  ...,  1.2317e-01,\n",
            "            5.2120e-02, -1.8930e-02],\n",
            "          [-4.4051e-01, -3.9851e-01, -3.5650e-01,  ...,  1.6995e-01,\n",
            "            1.1137e-01,  5.2792e-02],\n",
            "          [-4.5281e-01, -4.0275e-01, -3.5270e-01,  ...,  2.1673e-01,\n",
            "            1.7062e-01,  1.2452e-01],\n",
            "          ...,\n",
            "          [-3.9979e-01, -3.3126e-01, -2.6273e-01,  ...,  9.1695e-03,\n",
            "            3.7618e-02,  6.6066e-02],\n",
            "          [-4.2895e-01, -3.5347e-01, -2.7799e-01,  ..., -4.9957e-03,\n",
            "            2.7873e-02,  6.0741e-02],\n",
            "          [-4.5810e-01, -3.7568e-01, -2.9325e-01,  ..., -1.9161e-02,\n",
            "            1.8128e-02,  5.5417e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2234e-01, -2.3778e-01, -2.5323e-01,  ..., -6.4435e-01,\n",
            "           -6.6349e-01, -6.8262e-01],\n",
            "          [-1.8725e-01, -1.9961e-01, -2.1196e-01,  ..., -6.0929e-01,\n",
            "           -6.3584e-01, -6.6238e-01],\n",
            "          [-1.5217e-01, -1.6143e-01, -1.7070e-01,  ..., -5.7423e-01,\n",
            "           -6.0819e-01, -6.4215e-01],\n",
            "          ...,\n",
            "          [-3.2937e-01, -3.2015e-01, -3.1093e-01,  ..., -2.5704e-01,\n",
            "           -2.5957e-01, -2.6210e-01],\n",
            "          [-4.1739e-01, -4.0650e-01, -3.9561e-01,  ..., -3.4225e-01,\n",
            "           -3.3772e-01, -3.3318e-01],\n",
            "          [-5.0542e-01, -4.9285e-01, -4.8029e-01,  ..., -4.2747e-01,\n",
            "           -4.1587e-01, -4.0427e-01]],\n",
            "\n",
            "         [[-4.7712e-01, -4.4816e-01, -4.1920e-01,  ..., -1.9630e-01,\n",
            "           -1.9430e-01, -1.9230e-01],\n",
            "          [-4.1675e-01, -3.8556e-01, -3.5437e-01,  ..., -1.5336e-01,\n",
            "           -1.5717e-01, -1.6097e-01],\n",
            "          [-3.5638e-01, -3.2297e-01, -2.8955e-01,  ..., -1.1042e-01,\n",
            "           -1.2004e-01, -1.2965e-01],\n",
            "          ...,\n",
            "          [-2.2293e-01, -2.4196e-01, -2.6098e-01,  ..., -8.6142e-02,\n",
            "           -8.4960e-02, -8.3779e-02],\n",
            "          [-3.0271e-01, -3.1080e-01, -3.1890e-01,  ..., -6.8375e-02,\n",
            "           -6.1198e-02, -5.4021e-02],\n",
            "          [-3.8248e-01, -3.7965e-01, -3.7682e-01,  ..., -5.0609e-02,\n",
            "           -3.7436e-02, -2.4264e-02]],\n",
            "\n",
            "         [[ 3.1311e-02, -2.0131e-02, -7.1574e-02,  ..., -5.3505e-01,\n",
            "           -5.7503e-01, -6.1501e-01],\n",
            "          [ 4.4773e-02, -6.5238e-03, -5.7821e-02,  ..., -5.1058e-01,\n",
            "           -5.4856e-01, -5.8653e-01],\n",
            "          [ 5.8236e-02,  7.0836e-03, -4.4069e-02,  ..., -4.8612e-01,\n",
            "           -5.2208e-01, -5.5804e-01],\n",
            "          ...,\n",
            "          [ 1.0223e-03,  1.0753e-02,  2.0483e-02,  ...,  1.0137e-01,\n",
            "            9.0742e-02,  8.0110e-02],\n",
            "          [-2.6862e-02, -1.6693e-02, -6.5250e-03,  ...,  1.4012e-01,\n",
            "            1.3049e-01,  1.2086e-01],\n",
            "          [-5.4746e-02, -4.4140e-02, -3.3534e-02,  ...,  1.7886e-01,\n",
            "            1.7023e-01,  1.6161e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.7028e-02, -6.0819e-02, -2.4610e-02,  ..., -1.6417e-02,\n",
            "            2.5356e-02,  6.7129e-02],\n",
            "          [-7.6450e-02, -4.5681e-02, -1.4911e-02,  ..., -1.0889e-02,\n",
            "            2.7141e-02,  6.5170e-02],\n",
            "          [-5.5871e-02, -3.0542e-02, -5.2127e-03,  ..., -5.3599e-03,\n",
            "            2.8926e-02,  6.3211e-02],\n",
            "          ...,\n",
            "          [ 4.4393e-02,  2.2338e-02,  2.8180e-04,  ...,  3.3042e-02,\n",
            "            3.6779e-02,  4.0516e-02],\n",
            "          [ 8.1532e-02,  5.5023e-02,  2.8515e-02,  ...,  6.5704e-02,\n",
            "            6.2640e-02,  5.9575e-02],\n",
            "          [ 1.1867e-01,  8.7709e-02,  5.6748e-02,  ...,  9.8366e-02,\n",
            "            8.8500e-02,  7.8634e-02]],\n",
            "\n",
            "         [[-4.3186e-01, -3.9864e-01, -3.6542e-01,  ..., -6.2824e-01,\n",
            "           -6.4153e-01, -6.5482e-01],\n",
            "          [-4.2998e-01, -3.9878e-01, -3.6757e-01,  ..., -6.0168e-01,\n",
            "           -6.1855e-01, -6.3543e-01],\n",
            "          [-4.2810e-01, -3.9892e-01, -3.6973e-01,  ..., -5.7511e-01,\n",
            "           -5.9557e-01, -6.1603e-01],\n",
            "          ...,\n",
            "          [-6.3047e-01, -5.8857e-01, -5.4667e-01,  ..., -1.3894e-01,\n",
            "           -1.4852e-01, -1.5809e-01],\n",
            "          [-6.8215e-01, -6.4404e-01, -6.0593e-01,  ..., -1.0048e-01,\n",
            "           -1.1409e-01, -1.2770e-01],\n",
            "          [-7.3382e-01, -6.9951e-01, -6.6520e-01,  ..., -6.2030e-02,\n",
            "           -7.9668e-02, -9.7306e-02]],\n",
            "\n",
            "         [[-5.9848e-02, -1.6860e-02,  2.6127e-02,  ...,  3.1317e-01,\n",
            "            3.2029e-01,  3.2742e-01],\n",
            "          [-9.5583e-02, -5.4853e-02, -1.4123e-02,  ...,  2.9491e-01,\n",
            "            2.9388e-01,  2.9284e-01],\n",
            "          [-1.3132e-01, -9.2846e-02, -5.4373e-02,  ...,  2.7666e-01,\n",
            "            2.6746e-01,  2.5826e-01],\n",
            "          ...,\n",
            "          [ 8.4930e-02,  9.8234e-02,  1.1154e-01,  ...,  6.1671e-02,\n",
            "            9.3127e-02,  1.2458e-01],\n",
            "          [ 6.7357e-02,  8.0743e-02,  9.4128e-02,  ...,  8.7667e-02,\n",
            "            1.1806e-01,  1.4845e-01],\n",
            "          [ 4.9785e-02,  6.3252e-02,  7.6719e-02,  ...,  1.1366e-01,\n",
            "            1.4299e-01,  1.7232e-01]]]], grad_fn=<UpsampleBilinear2DBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
