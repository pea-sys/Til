{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch本1_5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgKZ4m+ZkzR54CFbA/qrsY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52c1ce7f882e4382ab4cc650de9d446c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff95b6007fb44a55857a74e759eea535",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b7e8c1fbeee942559f5ef5cc2f47d55b",
              "IPY_MODEL_ed22c01f788d4154a73f3175e7fba040"
            ]
          }
        },
        "ff95b6007fb44a55857a74e759eea535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7e8c1fbeee942559f5ef5cc2f47d55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aaff48b5246a447692dfcfc3208e010c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16b5c02c2df049cc9a9e1cb82a580793"
          }
        },
        "ed22c01f788d4154a73f3175e7fba040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f05014c28f954f229e22d6e3db0b8949",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 528M/528M [00:28&lt;00:00, 19.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02abc37b478e46db833a5071b0f08aaf"
          }
        },
        "aaff48b5246a447692dfcfc3208e010c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16b5c02c2df049cc9a9e1cb82a580793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f05014c28f954f229e22d6e3db0b8949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02abc37b478e46db833a5071b0f08aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pea-sys/Til/blob/master/PyTorch%E6%9C%AC1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3c_nhPJOxlj",
        "colab_type": "text"
      },
      "source": [
        "# 1.5 「ファインチューニング」で精度向上を実現する方法\n",
        "* 本ファイルでは、学習済みのVGGモデルを使用し、ファインチューニングでアリとハチの画像を分類するモデルを学習します\n",
        "\n",
        "# 学習目標\n",
        "\n",
        "\n",
        "1.   PyTorchでGPUを使用する実装コードを書けるようになる\n",
        "2.   最適化手法の設定において、層ごとに異なる学習率を設定したファインチューニングを実装できるようになる\n",
        "3.学習したネットワークを保存・ロードできるようになる\n",
        "\n",
        "[写経元](https://github.com/YutaroOgawa/pytorch_advanced/blob/master/1_image_classification/1-5_fine_tuning.ipynb)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-IDBxd8g6gP",
        "colab_type": "code",
        "outputId": "f126b6b7-669f-4f22-9ba9-d7a6b125aef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!pip install -U torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 22kB/s \n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 62.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.3.1\n",
            "    Uninstalling torch-1.3.1:\n",
            "      Successfully uninstalled torch-1.3.1\n",
            "  Found existing installation: torchvision 0.4.2\n",
            "    Uninstalling torchvision-0.4.2:\n",
            "      Successfully uninstalled torchvision-0.4.2\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahd1wp8sijQT",
        "colab_type": "code",
        "outputId": "cfeec87e-322e-4a0a-f04a-7825516dcf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "!git clone https://github.com/YutaroOgawa/pytorch_advanced.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_advanced'...\n",
            "remote: Enumerating objects: 441, done.\u001b[K\n",
            "remote: Total 441 (delta 0), reused 0 (delta 0), pack-reused 441\u001b[K\n",
            "Receiving objects: 100% (441/441), 14.62 MiB | 32.20 MiB/s, done.\n",
            "Resolving deltas: 100% (231/231), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI0U9pjjjfuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5EhKUmaj-l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# フォルダ「data」が存在しない場合は作成する\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVq16qzhkA3n",
        "colab_type": "code",
        "outputId": "9ead81cc-7280-4bde-ed20-d9ade3b02bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd pytorch_advanced/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch_advanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DC-6vI2kDOp",
        "colab_type": "code",
        "outputId": "4907fe74-7510-49ac-d384-7090b7fde852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd 1_image_classification/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch_advanced/1_image_classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7MW-3LynEsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.3節で使用するアリとハチの画像データをダウンロードし解凍します\n",
        "# PyTorchのチュートリアルで用意されているものです\n",
        "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "\n",
        "url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
        "save_path = os.path.join(data_dir, \"hymenoptera_data.zip\")\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "    # ZIPファイルを読み込み\n",
        "    zip = zipfile.ZipFile(save_path)\n",
        "    zip.extractall(data_dir)  # ZIPを解凍\n",
        "    zip.close()  # ZIPファイルをクローズ\n",
        "\n",
        "    # ZIPファイルを消去\n",
        "    os.remove(save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OeU1m6OkRXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# パッケージのimport\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIFj16_nkRwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 乱数のシードを設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgE_4QBjkTcI",
        "colab_type": "code",
        "outputId": "cd224c44-fcb3-42e4-95f6-d1cce867a576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 1.3節で作成したクラスを同じフォルダにあるmake_dataset_dataloader.pyに記載して使用\n",
        "from utils.dataloader_image_classification import ImageTransform, make_datapath_list, HymenopteraDataset\n",
        "# アリとハチの画像へのファイルパスのリストを作成する\n",
        "train_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"val\")\n",
        "\n",
        "# Datasetを作成する\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "train_dataset = HymenopteraDataset(\n",
        "    file_list=train_list, transform=ImageTransform(size, mean, std), phase='train')\n",
        "\n",
        "val_dataset = HymenopteraDataset(\n",
        "    file_list=val_list, transform=ImageTransform(size, mean, std), phase='val')\n",
        "\n",
        "\n",
        "# DataLoaderを作成する\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./data/hymenoptera_data/train/**/*.jpg\n",
            "./data/hymenoptera_data/val/**/*.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tDnLanDkVih",
        "colab_type": "code",
        "outputId": "218dc0a8-f7ca-4219-e084-ef33e08f4e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "52c1ce7f882e4382ab4cc650de9d446c",
            "ff95b6007fb44a55857a74e759eea535",
            "b7e8c1fbeee942559f5ef5cc2f47d55b",
            "ed22c01f788d4154a73f3175e7fba040",
            "aaff48b5246a447692dfcfc3208e010c",
            "16b5c02c2df049cc9a9e1cb82a580793",
            "f05014c28f954f229e22d6e3db0b8949",
            "02abc37b478e46db833a5071b0f08aaf"
          ]
        }
      },
      "source": [
        "# 学習済みのVGG-16モデルをロード\n",
        "\n",
        "# VGG-16モデルのインスタンスを生成\n",
        "use_pretrained = True  # 学習済みのパラメータを使用\n",
        "net = models.vgg16(pretrained=use_pretrained)\n",
        "\n",
        "# VGG16の最後の出力層の出力ユニットをアリとハチの2つに付け替える\n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52c1ce7f882e4382ab4cc650de9d446c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=553433881), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqpQyvWvnQxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGb2RPW-nUTJ",
        "colab_type": "code",
        "outputId": "e54e4ec7-d052-4375-a2d3-11443e9c4800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "# ファインチューニングで学習させるパラメータを、変数params_to_updateの1～3に格納する\n",
        "\n",
        "params_to_update_1 = []\n",
        "params_to_update_2 = []\n",
        "params_to_update_3 = []\n",
        "\n",
        "# 学習させる層のパラメータ名を指定\n",
        "update_param_names_1 = [\"features\"]\n",
        "update_param_names_2 = [\"classifier.0.weight\",\n",
        "                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "# パラメータごとに各リストに格納する\n",
        "for name, param in net.named_parameters():\n",
        "    if update_param_names_1[0] in name:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_1.append(param)\n",
        "        print(\"params_to_update_1に格納：\", name)\n",
        "\n",
        "    elif name in update_param_names_2:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_2.append(param)\n",
        "        print(\"params_to_update_2に格納：\", name)\n",
        "\n",
        "    elif name in update_param_names_3:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_3.append(param)\n",
        "        print(\"params_to_update_3に格納：\", name)\n",
        "\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "        print(\"勾配計算なし。学習しない：\", name)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params_to_update_1に格納： features.0.weight\n",
            "params_to_update_1に格納： features.0.bias\n",
            "params_to_update_1に格納： features.2.weight\n",
            "params_to_update_1に格納： features.2.bias\n",
            "params_to_update_1に格納： features.5.weight\n",
            "params_to_update_1に格納： features.5.bias\n",
            "params_to_update_1に格納： features.7.weight\n",
            "params_to_update_1に格納： features.7.bias\n",
            "params_to_update_1に格納： features.10.weight\n",
            "params_to_update_1に格納： features.10.bias\n",
            "params_to_update_1に格納： features.12.weight\n",
            "params_to_update_1に格納： features.12.bias\n",
            "params_to_update_1に格納： features.14.weight\n",
            "params_to_update_1に格納： features.14.bias\n",
            "params_to_update_1に格納： features.17.weight\n",
            "params_to_update_1に格納： features.17.bias\n",
            "params_to_update_1に格納： features.19.weight\n",
            "params_to_update_1に格納： features.19.bias\n",
            "params_to_update_1に格納： features.21.weight\n",
            "params_to_update_1に格納： features.21.bias\n",
            "params_to_update_1に格納： features.24.weight\n",
            "params_to_update_1に格納： features.24.bias\n",
            "params_to_update_1に格納： features.26.weight\n",
            "params_to_update_1に格納： features.26.bias\n",
            "params_to_update_1に格納： features.28.weight\n",
            "params_to_update_1に格納： features.28.bias\n",
            "params_to_update_2に格納： classifier.0.weight\n",
            "params_to_update_2に格納： classifier.0.bias\n",
            "params_to_update_2に格納： classifier.3.weight\n",
            "params_to_update_2に格納： classifier.3.bias\n",
            "params_to_update_3に格納： classifier.6.weight\n",
            "params_to_update_3に格納： classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax-NKvesnY4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 最適化手法の設定\n",
        "optimizer = optim.SGD([\n",
        "    {'params': params_to_update_1, 'lr': 1e-4},\n",
        "    {'params': params_to_update_2, 'lr': 5e-4},\n",
        "    {'params': params_to_update_3, 'lr': 1e-3}\n",
        "], momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viy0dR6nnd16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # 初期設定\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "            if (epoch == 0) and (phase == 'train'):\n",
        "                continue\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # 結果の計算\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率を表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-3lTXqSnhni",
        "colab_type": "code",
        "outputId": "925eee38-3dae-482c-e965-0817f3d84cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# 学習・検証を実行する\n",
        "num_epochs=2\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:04<00:00,  1.09s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7704 Acc: 0.4444\n",
            "Epoch 2/2\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:09<00:00,  1.57s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5121 Acc: 0.7119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.1810 Acc: 0.9477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXYlsLbtnkm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PyTorchのネットワークパラメータの保存\n",
        "save_path = './weights_fine_tuning.pth'\n",
        "torch.save(net.state_dict(), save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBK6Kibdnszy",
        "colab_type": "code",
        "outputId": "1181a75d-7bf8-42f3-b6cc-49f7456cb199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# PyTorchのネットワークパラメータのロード\n",
        "load_path = './weights_fine_tuning.pth'\n",
        "load_weights = torch.load(load_path)\n",
        "net.load_state_dict(load_weights)\n",
        "\n",
        "# GPU上で保存された重みをCPU上でロードする場合\n",
        "load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\n",
        "net.load_state_dict(load_weights)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q9CPjq2nwIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
