## 1.基礎的なアプローチ

- データが大量にあるのは確かだが、データから細大の価値を引き出すチャンスを得るには、データの処理を効率化しなければならない

* アルゴリズムが複雑になるに従い、計算コストも増大するため、計算による影響を抑える方法を見つけ出さなければならない
* GPU を活用できるようにする必要がある
* Python はパフォーマンス面で深刻な問題を抱えている。高度なアルゴリズムで大量のデータを処理するためには、そうした問題を回避できなければならない
* 問題のほとんどは解決可能。本書の目標は、選択肢となるソリューションを大量に鍾愛し、最適な方法と場所を示すことで効率的なソリューションを選択して実装できるようにすること

## 2.組込み機能のパフォーマンスを最大限に引き出す

- パフォーマンスのボトルネックは経験に基づくアプローチでほとんどうまくいく
- Python に組み込まれているプロファイリングシステムは、解釈が難しいことがある。ShakeViz のような可視化ツールが理解に役立つことがある

- line_profiler のようなツールを使うと、情報を収集するために実行がかなり遅くなることと引き換えに、精度を大幅に改善できる

- 最初にパフォーマンスの最適化の対象となるのは一般に CPU のパフォーマンスだが、メモリ使用量も同じくらい重要であり、間接的に大きなメリットをもたらす可能性がある。完全なインメモリアプローチに置き換え可能な場合、膨大な時間の節約になる

- Python の基本的なデータ構造は、パフォーマンスに影響を与えることがある。例えば順序無リストの検索のコストは高くなる。

- 遅延プログラミングテクニックを使って開発できるプログラムでは、メモリフットプリントが小さくなる傾向にある

## 3.並行性、並列性、非同期処理

- 非同期プログラミングは通信のニーズと必要な処理の量が少ない場合に（Web サーバーでも一般的なパターン)、多くの同時リクエストを効率よく処理するための効果的なアプローチになることがある

- Python のスレッディングは、パフォーマンスの改善にはあまり役立たない。GIL は 1 度に 1 つのスレッドだけを実行できることを要求する

- Python のマルチプロセッシングでは、ピュア Python のコードだけであっても、コンピュータの CPU コアを全て活用できる

- 一般的に、計算の粒度は粗く保つのが最も効果的である。通信が多すぎると、おそらくソリューションが低速になる。

- 並列コードを開発するときには、共有メモリと低レベルのロックは使わないようにする。それらが必要になった場合は、低水準限度で逐次的なソリューションを実装する

## 4.ハイパフォーマンスな NumPy

- 配列のビューは、メモリとパフォーマンスの両面で、コピーより大幅に効率的である。極力ビューを検討すべきである

- Numpy のビューメカニズムは十何であり、計算コストとメモリコストがほとんどかからない

- 形状とストライドを理解することは、ビューを最大限に活用するための基本条件

- 配列プログラミングでは、パフォーマンスを桁違いに改善できる。極力使うべきである

- Numpy のブロードキャストのルールにより、より効率的で洗練されたプログラミングが可能となる

- Numpy の内部アーキテクチャはコンピューティングパフォーマンスに合わせて最適化できる。Numpy は BLAS ライブラリと LAPACK ライブラリに依存しており、これらのライブラリに対してさまざまな実装が提供されている

- Numpy 実装が各自のアーキテクチャにとって最も効率的なライブラリを使っていることを確認する

- Numpy のスレッドセマンティクスは線形代数ライブラリのスレッドセマンティクスに依存するため、Numpy での並列プログラミングは一筋縄ではいかないことがある

- Numpy 実装に基づく Python ベースのマルチプロセッシングを使う前に、Numpy のベースになっているライブラリがマルチスレッディングを利用するかどうかを必ず理解しておく。マルチスレッディングを利用しない場合は、恐らくそれらのライブラリを変更すべきである。Numpy 呼び出し自体がマルチスレッドである場合は、その上でマルチプロセッシングを使わないようにすべきである。

## 5.Cython を使って重要なコードを再実装する

- ネイティブ Python、つまり CPython は複雑な演算に対する最速のコードを実装するのに十分ではない

- Python ベースのコードを高速化するときには、最適化されたライブラリ、低水準言語、Numba、または PyPy といったほかの Python 実装を使うなど、多くの選択肢がある

* Cython は Python のスーパーセットであり、C にコンパイルされ、C と同様の速度を実現する

* Cython のプロファイリングは Python のコードと同様の方法で実行できる

* 効率的な Cython コードを記述するには、型ヒントを提供するために、Cython の変数にアノテーションを追加する必要がある

* Cython が知恵協する C コードブラウザを使うと、Python インタープリタとやり取りする行を簡単に特定できる

* CPython とやり取りするコードはできるだけ取り除くべき

* Cython と Numpy は統合されており、配列を効率良く操作できるようになっている。メモリビューなどのリソースを使うと、Cython と Numpy の間で直接やり取りすることが可能になり、仲介者である非効率な Python インタープリタが排除される

* CPython に依存しないコードは、GIL に依存しないコードへの第一歩である

* Cython に変わる選択してとして忘れずに Numba を検討する。カスタマイズ性は劣るが Numba の方が使いやすい

## 6.メモリ階層、ストレージ、ネットワーク

- メモリ階層を意識することは、効率的なプログラムを設計するための基本である

- DRAM へのアクセスは CPU スタベーションを引き起こし、多くのサイクルにわたって CPU がアイドル状態に陥る。出来るだけ多くのデータが CPU キャッシュに配置されるようにすると、処理速度を大幅に向上させることが出来る

* CPU スタベーションを回避するアルゴリズムはより効率的である可能性があるが、直感的に理解しにくいことがある。例えば、圧縮／圧縮解除アルゴリズムのコストは RAM から非圧縮データを取得するコストより低い場合があり、RAW データより圧縮データを処理するほうが高速なことがある

* 多くの場合、Blosc を使うと、圧縮された状態で格納されたデータ表現に RAW データよりも高速にアクセスできる

* NumExpr では、NumPy より少ない時間と少ないメモリで NumPy 形式の指揮を処理できる。NumExpr はスマート L1 キャッシュなどのテクニックを活用して評価を拘束かする。場合によっては１桁以上の高速化が可能になる

* 現代のローカルネットワークは非常に高速であり、ネットワーク経由で他のコンピュータにアクセスするほうが、ローカルディスクにアクセスするよりも高速な場合がある

* 標準の REST API は高速なローカルネットワークを効率よく利用する場合は遅すぎる

## 7.ハイパフォーマンスな pandas と Apache Arrow

- pandas は Python の世界で最も広く使われているデータ分析ライブラリだが、計算量に関してもインメモリストレージに関しても小売り湯を第一に考えた設計にはなっていない

- データを読み込むための非常に単純なテクニックより、pandas データフレームのメモリフットプリントを大幅に削減できる

- pandas では、インデックスを賢く使うことで処理時間を削減できる

- 行を反復処理する戦略によっては、パフォーマンスに２桁以上の差が生じることがある。可能な限りベクトルを使うようにする

* pandas は Numpy に基づいて構築されているが、pnadas から Numpy のデータ構造の抽出を明示的に要求すると、パフォーマンスを改善できることがある

* Numpy のデータ構造を通じて間接的にであるが、Cython で pandas を使うこともでき、パフォーマンスを大幅に向上させることができる

* 非常に大きなデータフレームと複雑な数式の２つがそろっている場合は、NumExpr がデータ分析を実行するための効率的な戦略になる可能性がある

* Apache Arrow ではさまざまなタスクが実行できる。本章では、特にデータの高速なリーダーとして pandas をどのように補完できるかに焦点を合わせた

## 8.ビッグデータの格納

- fsspec はファイルストレージの統一インターフェイスとして機能し、様々なシュルのバックエンドで同じ API を利用できるようにする

- fsspec による統一 API があるため、バックエンドの置き換えが容易になる

- fsspec はパフォーマンスに直接関係しないが、Arrow や Zarr などの高度なライブラリで活用されている

- Parquet は、より効率的なデータの格納を可能にする列指向のデータフォーマット

- Parquet はディスク所なりや RLE 等の高度なデータエンコーディング戦略を使っており、明確なパターンと繰り返しがあるデータを非常にコンパクトに表現できる

- Parquet では、データのパーティション分割が可能であり、データの処理を並列化できる

- メモリに収まらない大きさのファイルを処理するための一般的な手法はチャンク化。pandas,parquet,zarr などのライブラリでサポートされている

- zarr は同種の多次元配列を処理するための現代的なライブラリである。Numpy ベースのインターフェイスを提供する。

- zarr は並列化を標準でサポートする。他のライブラリではめったに見られない同時書き込みプロセスのサポートがある。

## 9.GPU コンピューティングを使ったデータ分析

- CPU にはさまざまな問題に対処できる、一握りの非常に高速な演算装置が搭載されている。これに対し、GPU には同様のワークロードを実行すると想定される、膨大な数の低速な演算装置が搭載されている

- GPU 用のコードを記述するときには、GPU の計算モデルが CPU とは大きく異なっていて、従来の逐次的な CPU コンピューティングとは異なる考え方が求められることを認識する必要がある

- 標準の Python コードを GPU で直接実行することはできない

- GPU を直接プログラムする方法を知らなくても、GPU を利用できる Python ライブラリが既に多数存在する

- 多くの Python ライブラリでは、既存の CPU バージョンをほぼそのまま置き換えることが出来る。例えば、Cupy は GPU を操作するが、インターフェイスは NumPy のものと同様である。cuDF のインターフェースは pandas のものと同様である

- Numba は GPU のためのコードを生成できるが、既存の Python コードに Numba のアノテーションを追加するだけではほとんど価値がない。大規模な配列を処理する多くのアルゴリズムによって可能となる超並列化を探求するには、コードの設計を見直す必要がある

* Numba のコードは GPU に対するものであっても、Numpy とシームレスにやり取りできる

## 10.Dask を使ったビッグデータの分析

- Dask でも多くのマシンに計算を分散させることができる

- Dask ではデータフレームや配列などメモリの収まらないオブジェクトも操作できる

- Dask は pandas や numpy のような広く知られている API のサブセットを実装しているが、Dask は主に遅延評価であるため、Dask の API のセマンティクスは異なる

- Dask では実行の前にタスクグラフを調べることが出来るため、実行される計算を理解し、場合によっては、その計算を最適化するための別のアプローチを検討できる

- Dask では計算の実装方法を細かく制御できる。例えば、後の計算でデータを効率よく再利用するために、計算ノードにデータをローカルに永続化させることができる

- 後の計算の高速化に役立つ場合は、ノード間でデータを再分割できる。ただし、ノード間でのデータ転送が必要になるため、パフォーマンスが犠牲になる

- Dask には何種類かのスケジューラがある。その中でも分散スケジューラを利用する場合は、シングルマシンから大規模なクラスタまで、幅広いアーキテクチャに計算をデプロイできる

- Dask には dask.distributed というスケジューラがあり、シングルマシンから科学的なクラスタやクラウドまで、さまざまなアーキテクチャにタスクを割り当てることができる

- dask.distibued は分散アプリケーションの分析とプロファイリングに利用できる高機能なダッシュボードを提供する
