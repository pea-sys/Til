{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch -Tutorials-BegginerBlitz.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wNaUiB3lNYrT",
        "47b1QhZ_OSnC",
        "9gaUCe3fb6iK",
        "fRW0HWTScEwP",
        "uHMEjCW-lXkT",
        "pimCsEY_8YYH",
        "6jFPfFV2ByLH",
        "XpRoqyrKGDr3",
        "DwUenXj0LEIB",
        "H8T4_qspNexU",
        "csYhOAI-fnSd",
        "m0fM1izmgExn",
        "vk5f4uCkhjo_",
        "mREjkwl6hwun",
        "pt5JnGF3iBIA",
        "uGl6U-_0iQFQ"
      ],
      "authorship_tag": "ABX9TyPdXJ245FUo+jILb7N2ctVx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36f8f094043542c3bf0c48b3a9017950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c00eb0a1d6a64706987a93c7027f79ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d51e058d31094f9ba5700c031b517e97",
              "IPY_MODEL_3c91c4bc850146b0970000922212a1d9"
            ]
          }
        },
        "c00eb0a1d6a64706987a93c7027f79ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d51e058d31094f9ba5700c031b517e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9051d504cb56453fa903382c5dc54be7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_baa3a144a94949399a88b29626e5e18d"
          }
        },
        "3c91c4bc850146b0970000922212a1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f937a4c1694c4e7aab6ddc5b2d551c94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:30, 14819212.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61e1ddc4be6e4eb4bbe0876844c8c73d"
          }
        },
        "9051d504cb56453fa903382c5dc54be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "baa3a144a94949399a88b29626e5e18d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f937a4c1694c4e7aab6ddc5b2d551c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61e1ddc4be6e4eb4bbe0876844c8c73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pea-sys/Til/blob/master/PyTorch_Tutorials_BegginerBlitz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om1kJzreKiKZ",
        "colab_type": "text"
      },
      "source": [
        "[Original](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "# Getting Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiIpwE_5Kky4",
        "colab_type": "text"
      },
      "source": [
        "# Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TqsKXemKLIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugZoc8QSKwCB",
        "colab_type": "text"
      },
      "source": [
        "初期化されていないマトリックスが宣言されていますが、使用される前に明確な既知の値が含まれていません。初期化されていないマトリックスが作成されると、その時点で割り当てられたメモリにあった値が初期値として表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbrppXGdKoWD",
        "colab_type": "code",
        "outputId": "96bead5d-ee73-4c64-a1b9-7e815f0a2ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.4053e-36, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 2.8026e-45],\n",
            "        [0.0000e+00, 1.1210e-44, 0.0000e+00],\n",
            "        [1.4013e-45, 0.0000e+00, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Nk2qKXKzHM",
        "colab_type": "code",
        "outputId": "337ed11c-0380-4b2f-8644-974ddc5ae91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6833, 0.8213, 0.0148],\n",
            "        [0.5770, 0.4337, 0.6391],\n",
            "        [0.0227, 0.6080, 0.0616],\n",
            "        [0.0816, 0.6485, 0.8664],\n",
            "        [0.1652, 0.8055, 0.3425]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7D3nEsqK8e5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "ゼロで満たされたdtype longの行列を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVGsBB6GK2Pa",
        "colab_type": "code",
        "outputId": "d1524d6d-d0ac-471a-b486-e7832398f526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hUvjjtsLEV2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "データからテンソルを直接構築します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myPlubYDK_S6",
        "colab_type": "code",
        "outputId": "ab93b2fc-598b-46ca-e19e-ad571ae81ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLSoYDt1LTRw",
        "colab_type": "text"
      },
      "source": [
        "または、既存のテンソルに基づいてテンソルを作成します。ユーザーが新しい値を提供しない限り,これらのメソッドは、入力テンソルのプロパティを再利用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RNQ-Nf7LGyS",
        "colab_type": "code",
        "outputId": "53ee617c-5d4f-4c92-901c-7ff7d7fcfa93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-1.0737,  0.7733, -1.7551],\n",
            "        [-0.5004, -1.2820,  1.3587],\n",
            "        [-0.3883,  1.3063, -0.3548],\n",
            "        [-0.2154,  0.4203, -0.8156],\n",
            "        [ 0.4530,  0.1988, -0.8683]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJBPyrH1LlsM",
        "colab_type": "code",
        "outputId": "8069108c-98b4-47c8-dc6b-78bd0d0a65aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljbRq8VNL2tR",
        "colab_type": "text"
      },
      "source": [
        "# Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95rRXH_0L8mR",
        "colab_type": "text"
      },
      "source": [
        "操作には複数の構文があります。次の例では、加算操作を見ていきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfkE64y2LyxQ",
        "colab_type": "code",
        "outputId": "1bec12ff-ba68-48aa-f743-8153ef6397b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1478,  1.1331, -0.8321],\n",
            "        [ 0.1914, -1.0335,  2.3528],\n",
            "        [ 0.4262,  2.2252,  0.4037],\n",
            "        [-0.1270,  1.1167, -0.2670],\n",
            "        [ 0.8721,  0.5668, -0.6724]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAXnHVEgL_0U",
        "colab_type": "code",
        "outputId": "55cff904-7297-44fe-d944-d380c4de88f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1478,  1.1331, -0.8321],\n",
            "        [ 0.1914, -1.0335,  2.3528],\n",
            "        [ 0.4262,  2.2252,  0.4037],\n",
            "        [-0.1270,  1.1167, -0.2670],\n",
            "        [ 0.8721,  0.5668, -0.6724]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oHve4-PMQke",
        "colab_type": "text"
      },
      "source": [
        "引数として出力テンソルを提供する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UyJmNJkMGR9",
        "colab_type": "code",
        "outputId": "e0d4dba0-5f24-4609-ef65-de811f7b2250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1478,  1.1331, -0.8321],\n",
            "        [ 0.1914, -1.0335,  2.3528],\n",
            "        [ 0.4262,  2.2252,  0.4037],\n",
            "        [-0.1270,  1.1167, -0.2670],\n",
            "        [ 0.8721,  0.5668, -0.6724]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmUCeaM8MeGz",
        "colab_type": "text"
      },
      "source": [
        "Addition: in-place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VzoFfxOML8i",
        "colab_type": "code",
        "outputId": "202b5f89-9989-4d01-9194-3c191cb44e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1478,  1.1331, -0.8321],\n",
            "        [ 0.1914, -1.0335,  2.3528],\n",
            "        [ 0.4262,  2.2252,  0.4037],\n",
            "        [-0.1270,  1.1167, -0.2670],\n",
            "        [ 0.8721,  0.5668, -0.6724]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwq2fAfoMoFJ",
        "colab_type": "text"
      },
      "source": [
        "標準のNumPyのようなインデックス作成は、すべての添え字で使用できます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnjzTfyIMhkg",
        "colab_type": "code",
        "outputId": "5318314a-3b60-47e4-924a-cade72360b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.7733, -1.2820,  1.3063,  0.4203,  0.1988])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoiooi4xNARP",
        "colab_type": "text"
      },
      "source": [
        "サイズ変更：テンソルのサイズ変更/形状変更を行う場合は、torch.viewを使用できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U70XGr-oMqf-",
        "colab_type": "code",
        "outputId": "5fbde34e-c91d-4a7b-c545-e15abb9b0570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP_Jp01gNNVn",
        "colab_type": "text"
      },
      "source": [
        "1つの要素のテンソルがある場合、.item（）を使用してPythonの数値として値を取得します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQdTEn6kNDmk",
        "colab_type": "code",
        "outputId": "a5267fc6-0378-4df8-e5ba-c620e9fa7759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.4781])\n",
            "-0.47805556654930115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNaUiB3lNYrT",
        "colab_type": "text"
      },
      "source": [
        "# NumPy Bridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFEhPoFuNd6W",
        "colab_type": "text"
      },
      "source": [
        "トーチテンソルをNumPy配列に、またはその逆に変換するのは簡単です。\n",
        "\n",
        "トーチテンソルとNumPyアレイは、基礎となるメモリ位置を共有し（トーチテンソルがCPU上にある場合）、一方を変更すると他方も変更されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UBpjBKMNiNx",
        "colab_type": "text"
      },
      "source": [
        "トーチテンソルからNumPy配列への変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgwKWxCyNQJJ",
        "colab_type": "code",
        "outputId": "9be1b438-0ee6-42ba-91a0-f8a12f9cd9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UzHOM7tNlPQ",
        "colab_type": "code",
        "outputId": "b322e6d6-17cd-40f3-ec21-574426070776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPXQHUCKNy8S",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "numpy配列の値の変化をご覧ください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBQweo49NnCN",
        "colab_type": "code",
        "outputId": "02e9a24e-20d5-4f88-e3dd-eb6de4253290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6acvZ6b3N9e1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "NumPy配列をトーチテンソルに変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwDummC8OLkY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "np配列を変更すると、トーチテンソルがどのように自動的に変更されたかをご覧ください"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ4U4ugVN1UX",
        "colab_type": "code",
        "outputId": "90e28696-6ede-4b0a-bec8-a7a73c03a2f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47b1QhZ_OSnC",
        "colab_type": "text"
      },
      "source": [
        "# CUDA Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP3vX18SOYKX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        ".toメソッドを使用して、テンソルを任意のデバイスに移動できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj2qIMD5OOnU",
        "colab_type": "code",
        "outputId": "85fdfb74-8e87-4aa4-f3e2-5876d9ad2dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.5219], device='cuda:0')\n",
            "tensor([0.5219], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gaUCe3fb6iK",
        "colab_type": "text"
      },
      "source": [
        "# AUTOGRAD: AUTOMATIC DIFFERENTIATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co0XvXskcCX3",
        "colab_type": "text"
      },
      "source": [
        "PyTorchのすべてのニューラルネットワークの中心は、autogradパッケージです。最初にこれを簡単に見てみましょう。次に、最初のニューラルネットワークのトレーニングに進みます。\n",
        "\n",
        "autogradパッケージは、Tensorのすべての操作を自動的に区別します。これは、実行ごとに定義されるフレームワークです。つまり、コードの実行方法によってbackpropが定義され、すべての反復が異なる場合があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRW0HWTScEwP",
        "colab_type": "text"
      },
      "source": [
        "# Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFDaMLetjJRR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "torch.Tensorは、パッケージの中心的なクラスです。属性.requires_gradをTrueに設定すると、すべての操作の追跡が開始されます。計算が終了したら、.backward（）を呼び出して、すべての勾配を自動的に計算できます。このテンソルの勾配は.grad属性に蓄積されます。\n",
        "\n",
        "テンソルが履歴を追跡しないようにするには、.detach（）を呼び出して計算履歴からデタッチし、将来の計算が追跡されないようにします。\n",
        "\n",
        "履歴の追跡（およびメモリの使用）を防ぐために、torch.no_grad（）：でコードブロックをラップすることもできます。モデルには、requires_grad = Trueのトレーニング可能なパラメーターがありますが、勾配は必要ないため、モデルを評価する際に特に役立ちます。\n",
        "\n",
        "autogradの実装に非常に重要なもう1つのクラス、Functionがあります。\n",
        "\n",
        "テンソルと関数は相互接続され、計算の完全な履歴をエンコードする非循環グラフを構築します。各テンソルには、Tensorを作成したFunctionを参照する.grad_fn属性があります（ユーザーが作成したTensorを除く-grad_fnはNoneです）。\n",
        "\n",
        "導関数を計算する場合は、Tensorで.backward（）を呼び出すことができます。 Tensorがスカラーの場合（つまり、1つの要素のデータを保持する場合）、backward（）に引数を指定する必要はありませんが、要素がさらにある場合は、一致する形状のテンソルである勾配引数を指定する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x25XOB5OcVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFflb5h4jlp8",
        "colab_type": "text"
      },
      "source": [
        "テンソルを作成し、requires_grad = Trueを設定して計算を追跡します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDFyFI55jMcf",
        "colab_type": "code",
        "outputId": "4b12f69d-f21c-4a2d-b736-a469d6627f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VReB3fD1juge",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "テンソル操作を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wKU9E6CjpMt",
        "colab_type": "code",
        "outputId": "99fc748b-418f-4281-a6c8-5883baf0dfd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t50Cz4sJkQWQ",
        "colab_type": "text"
      },
      "source": [
        "yは操作の結果として作成されたため、grad_fnがあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnFBvO-mkLZ9",
        "colab_type": "code",
        "outputId": "73c55310-0291-40e2-e520-981988a9b932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7fcde4d4d860>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8K9gJ_vkds7",
        "colab_type": "text"
      },
      "source": [
        "yでさらに操作を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r54H6DVJkWO4",
        "colab_type": "code",
        "outputId": "144d48db-08b5-4fb1-fe14-65fabef830f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb3roSywlA2F",
        "colab_type": "text"
      },
      "source": [
        ".requires_grad_（...）は、既存のTensorのrequire_gradフラグをその場で変更します。入力フラグは、指定されていない場合のデフォルトのFalseです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8-EJcSUkwBZ",
        "colab_type": "code",
        "outputId": "78f0bc42-c8ed-430b-e373-2216ddf8c476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7fcddc7131d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHMEjCW-lXkT",
        "colab_type": "text"
      },
      "source": [
        "# Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Asd5lblbC8",
        "colab_type": "text"
      },
      "source": [
        "outには単一のスカラーが含まれているため、out.backward（）はout.backward（torch.tensor（1。））と同等です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TJq_xi9lMAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI3vE2F1wAd8",
        "colab_type": "text"
      },
      "source": [
        "Print gradients d(out)/dx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FIgIeVwl8en",
        "colab_type": "code",
        "outputId": "6d17edca-503f-403d-9cdf-fc78dcf074a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rT1w13Pxofw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "ベクトルヤコビ積のこの特性により、非スカラー出力を持つモデルに外部勾配を供給することが非常に便利になります。\n",
        "次に、ベクトルヤコビ積の例を見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JhZ-09axtSL",
        "colab_type": "code",
        "outputId": "e971e2e3-c1d0-43cd-8c2d-181fa9897fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1081.8945,  -593.1576,  -854.6824], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIgsdkDF573Q",
        "colab_type": "text"
      },
      "source": [
        "この場合、yはスカラーではなくなりました。 torch.autogradは完全なヤコビアンを直接計算できませんでしたが、ベクトルとヤコビアンの積だけが必要な場合は、単にベクトルを引数として逆方向に渡します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un18AJScxwC0",
        "colab_type": "code",
        "outputId": "be54fa6e-9761-4195-b7ea-6a1c8ea5e171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snazpz3g66oG",
        "colab_type": "text"
      },
      "source": [
        "また、コードブロックをtorch.no_grad（）でラップすることにより、.requires_grad = TrueでTensorの履歴の追跡からautogradを停止することもできます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDm7LIne6Pq9",
        "colab_type": "code",
        "outputId": "119e2dee-61bd-48c5-b943-c141bca7091e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBQSUe4f7G2M",
        "colab_type": "code",
        "outputId": "9c1e16fa-e7d3-49f6-8ed3-7a92afe0f3e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pimCsEY_8YYH",
        "colab_type": "text"
      },
      "source": [
        "# NEURAL NETWORKS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eORCqImI9Vya",
        "colab_type": "text"
      },
      "source": [
        "ニューラルネットワークは、torch.nnパッケージを使用して構築できます。\n",
        "\n",
        "autogradを垣間見ると、nnはautogradに依存してモデルを定義し、モデルを区別します。 nn.Moduleにはレイヤーと、出力を返すforward（input）メソッドが含まれます。\n",
        "\n",
        "たとえば、数字画像を分類するこのネットワークを見てください："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvbv_nShBKQl",
        "colab_type": "text"
      },
      "source": [
        "これは、単純なフィードフォワードネットワークです。入力を受け取り、いくつかのレイヤーを次々に通過させ、最終的に出力を提供します。\n",
        "\n",
        "ニューラルネットワークの一般的なトレーニング手順は次のとおりです。\n",
        "\n",
        "* 学習可能なパラメーター（または重み）を持つニューラルネットワークを定義する\n",
        "* 入力のデータセットを反復処理する\n",
        "* ネットワークを介した入力の処理\n",
        "* 損失を計算します（出力が正しいことからどれくらい離れているか）\n",
        "* 勾配をネットワークのパラメーターに伝播します\n",
        "* 通常、単純な更新ルールを使用して、ネットワークの重みを更新します：weight = weight-learning_rate * gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jFPfFV2ByLH",
        "colab_type": "text"
      },
      "source": [
        "# Define the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q4H9ymMBACp",
        "colab_type": "code",
        "outputId": "29305828-2db6-4b8b-900b-907ab9fd7416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQPdTvwCFGt5",
        "colab_type": "text"
      },
      "source": [
        "フォワード関数を定義するだけで、autogradを使用してバックワード関数（勾配が計算される）が自動的に定義されます。 forward関数で任意のTensor操作を使用できます。/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpN1SB6jEndf",
        "colab_type": "code",
        "outputId": "90e0de85-f8f7-4cd2-8b75-9ca5445aeeda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1's .weight"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mmOLlwPFsCH",
        "colab_type": "text"
      },
      "source": [
        "ランダムな32x32入力を試してみましょう。注：このネット（LeNet）の予想入力サイズは32x32です。 MNISTデータセットでこのネットを使用するには、データセットから32x32に画像のサイズを変更してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u99yZb86FKju",
        "colab_type": "code",
        "outputId": "8687ba63-c859-45e4-f9a6-3e3c6ed8b019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0629, -0.0274,  0.1297,  0.0747, -0.0738,  0.0802, -0.0427, -0.0321,\n",
            "         -0.0746, -0.0661]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wLGlk1xFz9y",
        "colab_type": "text"
      },
      "source": [
        "すべてのパラメーターの勾配バッファーをゼロにし、ランダム勾配でバックプロップします："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGYULjyUFuom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpRoqyrKGDr3",
        "colab_type": "text"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS8svvpMHIN7",
        "colab_type": "text"
      },
      "source": [
        "損失関数は、入力（出力、ターゲット）のペアを受け取り、出力がターゲットからどれだけ離れているかを推定する値を計算します。\n",
        "\n",
        "nnパッケージにはいくつかの異なる損失関数があります。単純な損失は、nn.MSELossです。これは、入力とターゲット間の平均二乗誤差を計算します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfwKCEGCHVc-",
        "colab_type": "code",
        "outputId": "de1c4780-7914-4778-d033-1888e2847ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "print(target)\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "print(target)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.3710, -1.0748, -0.0938,  0.8789,  0.0684,  1.5615, -0.0418,  2.5326,\n",
            "        -0.1765,  0.0957])\n",
            "tensor([[ 0.3710, -1.0748, -0.0938,  0.8789,  0.0684,  1.5615, -0.0418,  2.5326,\n",
            "         -0.1765,  0.0957]])\n",
            "tensor(1.0811, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lqUQ-xYIVJD",
        "colab_type": "text"
      },
      "source": [
        "ここで、.grad_fn属性を使用して逆方向の損失を追跡すると、次のような計算のグラフが表示されます。\n",
        "\n",
        "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
        "      -> view -> linear -> relu -> linear -> relu -> linear\n",
        "      -> MSELoss\n",
        "      -> loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7dARQK6JA-f",
        "colab_type": "text"
      },
      "source": [
        "したがって、loss.backward（）を呼び出すと、グラフ全体がw.r.tと区別されます。損失と、requires_grad = Trueを持つグラフ内のすべてのTensorには、勾配とともに.grad Tensorが蓄積されます。\n",
        "\n",
        "例として、後方にいくつかのステップをたどってみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGWWFxL2HMVu",
        "colab_type": "code",
        "outputId": "e5c4a07b-9e2f-4466-9069-91032dd0941c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(loss.grad_fn)  # MSELoss\n",
        "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7fcddc713da0>\n",
            "<AddmmBackward object at 0x7fcddc7131d0>\n",
            "<AccumulateGrad object at 0x7fcddc713da0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwUenXj0LEIB",
        "colab_type": "text"
      },
      "source": [
        "# Backprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0an6rgnyLKxg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "エラーを逆伝播するために必要なのは、loss.backward（）だけです。ただし、既存のグラデーションをクリアする必要があります。クリアしないと、既存のグラデーションにグラデーションが蓄積されます。\n",
        "\n",
        "ここで、loss.backward（）を呼び出し、逆方向の前後のconv1のバイアス勾配を見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WlrUkjbJn3g",
        "colab_type": "code",
        "outputId": "04570874-5ba5-4390-e6dc-1042eae2ebd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.0213, -0.0054, -0.0005, -0.0050,  0.0015, -0.0032])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8T4_qspNexU",
        "colab_type": "text"
      },
      "source": [
        "# Update the weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TKfR7fCN_O2",
        "colab_type": "text"
      },
      "source": [
        "実際に使用される最も単純な更新ルールは、確率的勾配降下法（SGD）です。\n",
        "\n",
        "重み=重み-learning_rate *勾配"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxVob-ebMv0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "    f.data.sub_(f.grad.data * learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIlgdyEjZ1dF",
        "colab_type": "text"
      },
      "source": [
        "ただし、ニューラルネットワークを使用する場合は、SGD、Nesterov-SGD、Adam、RMSPropなどのさまざまな更新ルールを使用する必要があります。これを有効にするために、これらすべてのメソッドを実装する小さなパッケージtorch.optimを構築しました。使い方はとても簡単です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGXYr41CZvdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# in your training loop:\n",
        "optimizer.zero_grad()   # zero the gradient buffers\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()    # Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csYhOAI-fnSd",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING A CLASSIFIER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYaiCngDfxMG",
        "colab_type": "text"
      },
      "source": [
        "ニューラルネットワークを定義し、損失を計算し、ネットワークの重みを更新する方法を見てきました。\n",
        "\n",
        "データはどうですか？\n",
        "一般に、画像、テキスト、オーディオ、またはビデオのデータを処理する必要がある場合、numpy配列にデータをロードする標準のPythonパッケージを使用できます。次に、この配列をtorch。* Tensorに変換できます。\n",
        "\n",
        "画像の場合、Pillow、OpenCVなどのパッケージが便利です\n",
        "オーディオの場合、scipyやlibrosaなどのパッケージ\n",
        "テキストの場合は、生のPythonまたはCythonベースの読み込み、またはNLTKとSpaCyが便利です\n",
        "具体的には、ビジョンのために、Imagenet、CIFAR10、MNISTなどの一般的なデータセットのデータローダーと、イメージのデータトランスフォーマー、つまり、torchvision.datasetsおよびtorch.utils.data.DataLoaderを含むtorchvisionというパッケージを作成しました。\n",
        "\n",
        "これにより、非常に便利になり、定型的なコードを書く必要がなくなります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zjp1y1WgAap",
        "colab_type": "text"
      },
      "source": [
        "このチュートリアルでは、CIFAR10データセットを使用します。 「飛行機」、「自動車」、「鳥」、「猫」、「鹿」、「犬」、「カエル」、「馬」、「船」、「トラック」のクラスがあります。 CIFAR-10の画像のサイズは3x32x32です。つまり、サイズが32x32ピクセルの3チャンネルカラー画像です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0fM1izmgExn",
        "colab_type": "text"
      },
      "source": [
        "# Training an image classifier\n",
        "\n",
        "次の手順を順番に実行します。\n",
        "\n",
        "torchvisionを使用してCIFAR10トレーニングおよびテストデータセットを読み込み、正規化する\n",
        "\n",
        "1.  畳み込みニューラルネットワークを定義する\n",
        "2.  損失関数を定義する\n",
        "3.  トレーニングデータでネットワークをトレーニングする\n",
        "4.  テストデータでネットワークをテストする\n",
        "\n",
        "# 1. Loading and normalizing CIFAR10\n",
        "\n",
        "トーチビジョンを使用すると、CIFAR10を非常に簡単にロードできます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUK4x1pFZ5Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU7M1gIFgx6-",
        "colab_type": "text"
      },
      "source": [
        "トーチビジョンデータセットの出力は、範囲[0、1]のPILImage画像です。それらを正規化された範囲[-1、1]のテンソルに変換します。   \n",
        ".. 注意：Windowsで実行しているときにBrokenPipeErrorが発生する場合は、設定してみてください\n",
        "torch.utils.data.DataLoader（）のnum_workerを0にします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGdfjuJygs-7",
        "colab_type": "code",
        "outputId": "460b01e2-af9e-4153-bc50-c1cac1e3c7fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "36f8f094043542c3bf0c48b3a9017950",
            "c00eb0a1d6a64706987a93c7027f79ba",
            "d51e058d31094f9ba5700c031b517e97",
            "3c91c4bc850146b0970000922212a1d9",
            "9051d504cb56453fa903382c5dc54be7",
            "baa3a144a94949399a88b29626e5e18d",
            "f937a4c1694c4e7aab6ddc5b2d551c94",
            "61e1ddc4be6e4eb4bbe0876844c8c73d"
          ]
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36f8f094043542c3bf0c48b3a9017950",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0bMctfBhVIm",
        "colab_type": "text"
      },
      "source": [
        "いくつかのトレーニング画像をお楽しみください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0pfOpF4hNHH",
        "colab_type": "code",
        "outputId": "e4a0edef-a004-4105-9513-e5e66f3839cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQEBAU2K/weoRCwDuXxoYgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  car  deer   cat horse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk5f4uCkhjo_",
        "colab_type": "text"
      },
      "source": [
        "# 2. Define a Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXXZQn0ThqNy",
        "colab_type": "text"
      },
      "source": [
        "前にニューラルネットワークセクションからニューラルネットワークをコピーし、（定義された1チャンネル画像ではなく）3チャンネル画像を取得するように変更します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JjOlidPhZNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mREjkwl6hwun",
        "colab_type": "text"
      },
      "source": [
        "# 3 3. Define a Loss function and optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCrLFti_hwc1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "運動量のある分類クロスエントロピー損失とSGDを使用しましょう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52h-XvhlhuFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt5JnGF3iBIA",
        "colab_type": "text"
      },
      "source": [
        "# 4. Train the network\n",
        "これは、物事が面白くなり始めるときです。データイテレータをループし、入力をネットワークに送り、最適化するだけです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEQ-QLuRh8rT",
        "colab_type": "code",
        "outputId": "ca50da1d-eba2-4741-8351-33f37ff81d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.206\n",
            "[1,  4000] loss: 1.903\n",
            "[1,  6000] loss: 1.692\n",
            "[1,  8000] loss: 1.627\n",
            "[1, 10000] loss: 1.565\n",
            "[1, 12000] loss: 1.488\n",
            "[2,  2000] loss: 1.417\n",
            "[2,  4000] loss: 1.387\n",
            "[2,  6000] loss: 1.360\n",
            "[2,  8000] loss: 1.352\n",
            "[2, 10000] loss: 1.316\n",
            "[2, 12000] loss: 1.309\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtTiWwtniJ9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGl6U-_0iQFQ",
        "colab_type": "text"
      },
      "source": [
        "# 5. Test the network on the test data\n",
        "トレーニングデータセットで2パスのネットワークをトレーニングしました。ただし、ネットワークが何かを学習したかどうかを確認する必要があります。\n",
        "\n",
        "これを確認するには、ニューラルネットワークが出力するクラスラベルを予測し、グラウンドトゥルースと照合します。予測が正しい場合、サンプルを正しい予測のリストに追加します。\n",
        "\n",
        "さて、最初のステップ。テストセットの画像を表示して、慣れてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FrBWzfbiUEZ",
        "colab_type": "code",
        "outputId": "47fbaac4-2ac9-4cb8-ee25-6bf90d38807d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxf8HV/T+BepgTjgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:    cat  ship  ship plane\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18hmnAMYilRQ",
        "colab_type": "text"
      },
      "source": [
        "次に、保存したモデルをロードし直します（注：モデルの保存と再ロードはここでは必要ありません。その方法を説明するためだけに行いました）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM0UAflyidql",
        "colab_type": "code",
        "outputId": "87165235-b8be-4a16-b04d-e6c1dd1da630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCcQDVZxivlZ",
        "colab_type": "text"
      },
      "source": [
        "では、ニューラルネットワークが上記の例をどのように考えているのか見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQvflcyJipii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = net(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl_JnxBni17t",
        "colab_type": "text"
      },
      "source": [
        "出力は、10クラスのエネルギーです。クラスのエネルギーが高いほど、ネットワークはその画像が特定のクラスのものであると考えます。それでは、最高のエネルギーのインデックスを取得しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2RnRhY6ixoI",
        "colab_type": "code",
        "outputId": "249cf4b4-6cbe-4abb-d2fd-e6bf52085ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:    cat   car   car  ship\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiSTq37QjDt4",
        "colab_type": "text"
      },
      "source": [
        "結果はかなり良いようです。\n",
        "\n",
        "ネットワークがデータセット全体でどのように機能するかを見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geds3MvUi49F",
        "colab_type": "code",
        "outputId": "0b6fb465-eb80-41fb-a009-f7628e319249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 51 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0q46WvejMbA",
        "colab_type": "text"
      },
      "source": [
        "これは、10％の精度（10個のクラスからランダムにクラスを選択する）である偶然よりもはるかに良いように見えます。ネットワークが何かを学んだようです。\n",
        "\n",
        "うーん、うまく機能したクラスとうまく機能しなかったクラスは何ですか："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjeQuCNXjHLx",
        "colab_type": "code",
        "outputId": "7d82d6b6-9b84-47e9-c97d-a1b23665a165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 62 %\n",
            "Accuracy of   car : 81 %\n",
            "Accuracy of  bird : 34 %\n",
            "Accuracy of   cat : 32 %\n",
            "Accuracy of  deer : 27 %\n",
            "Accuracy of   dog : 40 %\n",
            "Accuracy of  frog : 77 %\n",
            "Accuracy of horse : 43 %\n",
            "Accuracy of  ship : 61 %\n",
            "Accuracy of truck : 59 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZASA2NgjUJi",
        "colab_type": "text"
      },
      "source": [
        "さて、次は何ですか？\n",
        "\n",
        "これらのニューラルネットワークをGPUで実行するにはどうすればよいですか？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-KR_0mxjWuL",
        "colab_type": "text"
      },
      "source": [
        "# Training on GPU\n",
        "TensorをGPUに転送するのと同じように、ニューラルネットをGPUに転送します。\n",
        "\n",
        "CUDAを利用できる場合、最初に表示されるcudaデバイスとしてデバイスを定義しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUEYwwoljPsm",
        "colab_type": "code",
        "outputId": "c1029b8b-cf53-4909-80dd-115ce70c2ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWgQ1KtdjhO_",
        "colab_type": "text"
      },
      "source": [
        "このセクションの残りの部分では、デバイスがCUDAデバイスであると想定しています。\n",
        "\n",
        "次に、これらのメソッドはすべてのモジュールを再帰的に調べて、パラメーターとバッファーをCUDAテンソルに変換します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjLhLrDwjde-",
        "colab_type": "code",
        "outputId": "60212f5e-232f-4436-acc5-31919157a4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "net.to(device)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsPWeCxHjnjl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "すべてのステップで入力とターゲットもGPUに送信する必要があることに注意してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXo3StuMjjHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs, labels = data[0].to(device), data[1].to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0DakDh-jtYY",
        "colab_type": "text"
      },
      "source": [
        "CPUと比較して大幅な高速化に気付かないのはなぜですか？あなたのネットワークは本当に小さいから"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEDn5jhYekV",
        "colab_type": "text"
      },
      "source": [
        "# OPTIONAL: DATA PARALLELISM\n",
        "このチュートリアルでは、DataParallelを使用して複数のGPUを使用する方法を学習します。\n",
        "\n",
        "PyTorchでGPUを使用するのは非常に簡単です。モデルをGPUに配置できます。  \n",
        "\n",
        "\n",
        "```\n",
        "device = torch.device(\"cuda:0\")\n",
        "model.to(device)\n",
        "```\n",
        "次に、すべてのテンソルをGPUにコピーできます。\n",
        "\n",
        "\n",
        "```\n",
        "mytensor = my_tensor.to(device)\n",
        "```\n",
        "\n",
        "my_tensor.to（device）を呼び出すだけで、my_tensorを書き換える代わりに、GPUでmy_tensorの新しいコピーが返されることに注意してください。新しいテンソルに割り当てて、GPUでそのテンソルを使用する必要があります。\n",
        "\n",
        "複数のGPUで前方伝播、後方伝播を実行するのは自然です。ただし、Pytorchはデフォルトで1つのGPUのみを使用します。 DataParallelを使用してモデルを並列実行することにより、複数のGPUで操作を簡単に実行できます。\n",
        "\n",
        "\n",
        "```\n",
        "model = nn.DataParallel(model)\n",
        "```\n",
        "\n",
        "これが、このチュートリアルの背後にあるコアです。以下で詳しく説明します。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sG4WFN3Zbo3",
        "colab_type": "text"
      },
      "source": [
        "# Imports and parameters\n",
        "PyTorchモジュールをインポートし、パラメーターを定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_hlocFZYf0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Parameters and DataLoaders\n",
        "input_size = 5\n",
        "output_size = 2\n",
        "\n",
        "batch_size = 30\n",
        "data_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TtqQ4NKYnBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd4yLBr2ZlrB",
        "colab_type": "text"
      },
      "source": [
        "# Dummy DataSet\n",
        "ダミー（ランダム）データセットを作成します。あなただけのgetitemを実装する必要があります"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_bMXG21ZjYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, size, length):\n",
        "        self.len = length\n",
        "        self.data = torch.randn(length, size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size),\n",
        "                         batch_size=batch_size, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOfzQZVEZyYQ",
        "colab_type": "text"
      },
      "source": [
        "# Simple Model\n",
        "デモでは、モデルは入力を取得し、線形演算を実行し、出力を生成します。ただし、任意のモデル（CNN、RNN、Capsule Netなど）でDataParallelを使用できます。\n",
        "\n",
        "入力および出力テンソルのサイズを監視するために、モデル内にprintステートメントを配置しました。バッチランク0で印刷されるものに注意してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6x4JNRHZsT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    # Our model\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.fc(input)\n",
        "        print(\"\\tIn Model: input size\", input.size(),\n",
        "              \"output size\", output.size())\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cuMSOPsZ_C_",
        "colab_type": "text"
      },
      "source": [
        "# Create Model and DataParallel\n",
        "これはチュートリアルの中心部分です。まず、モデルインスタンスを作成し、複数のGPUがあるかどうかを確認する必要があります。複数のGPUがある場合、nn.DataParallelを使用してモデルをラップできます。次に、model.to（device）によってGPUにモデルを配置できます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT7ZZoCqZ8sU",
        "colab_type": "code",
        "outputId": "8022fa97-1351-4513-ab09-1a00665ac703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model = Model(input_size, output_size)\n",
        "if torch.cuda.device_count() > 1:\n",
        "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
        "  model = nn.DataParallel(model)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc): Linear(in_features=5, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO0OSa1RbCOW",
        "colab_type": "text"
      },
      "source": [
        "# Run the Model\n",
        "これで、入力テンソルと出力テンソルのサイズを確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDdP18_wa_a1",
        "colab_type": "code",
        "outputId": "9a922a08-6384-465e-9173-ee10ce9dc822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "for data in rand_loader:\n",
        "    input = data.to(device)\n",
        "    output = model(input)\n",
        "    print(\"Outside: input size\", input.size(),\n",
        "          \"output_size\", output.size())"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tIn Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
            "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
            "\tIn Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
            "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
            "\tIn Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
            "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
            "\tIn Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
            "Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL7-1uuoeqj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b68c4f7-8253-45dc-9d42-216d99beb40d"
      },
      "source": [
        "!apt-get install lshw\n",
        "!lshw"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "lshw is already the newest version (02.18-0.1ubuntu6.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "609afeaa60b3\n",
            "    description: Computer\n",
            "    width: 64 bits\n",
            "    capabilities: smp vsyscall32\n",
            "  *-core\n",
            "       description: Motherboard\n",
            "       physical id: 0\n",
            "     *-memory\n",
            "          description: System memory\n",
            "          physical id: 0\n",
            "          size: 12GiB\n",
            "     *-cpu\n",
            "          product: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "          vendor: Intel Corp.\n",
            "          physical id: 1\n",
            "          bus info: cpu@0\n",
            "          width: 64 bits\n",
            "          capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp x86-64 constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "     *-pci\n",
            "          description: Host bridge\n",
            "          product: 440FX - 82441FX PMC [Natoma]\n",
            "          vendor: Intel Corporation\n",
            "          physical id: 100\n",
            "          bus info: pci@0000:00:00.0\n",
            "          version: 02\n",
            "          width: 32 bits\n",
            "          clock: 33MHz\n",
            "        *-isa\n",
            "             description: ISA bridge\n",
            "             product: 82371AB/EB/MB PIIX4 ISA\n",
            "             vendor: Intel Corporation\n",
            "             physical id: 1\n",
            "             bus info: pci@0000:00:01.0\n",
            "             version: 03\n",
            "             width: 32 bits\n",
            "             clock: 33MHz\n",
            "             capabilities: isa\n",
            "             configuration: latency=0\n",
            "        *-bridge UNCLAIMED\n",
            "             description: Bridge\n",
            "             product: 82371AB/EB/MB PIIX4 ACPI\n",
            "             vendor: Intel Corporation\n",
            "             physical id: 1.3\n",
            "             bus info: pci@0000:00:01.3\n",
            "             version: 03\n",
            "             width: 32 bits\n",
            "             clock: 33MHz\n",
            "             capabilities: bridge\n",
            "             configuration: latency=0\n",
            "        *-generic:0\n",
            "             description: Non-VGA unclassified device\n",
            "             product: Virtio SCSI\n",
            "             vendor: Red Hat, Inc.\n",
            "             physical id: 3\n",
            "             bus info: pci@0000:00:03.0\n",
            "             version: 00\n",
            "             width: 32 bits\n",
            "             clock: 33MHz\n",
            "             capabilities: msix bus_master cap_list\n",
            "             configuration: driver=virtio-pci latency=0\n",
            "             resources: irq:11 ioport:c000(size=64) memory:fd000000-fd00007f\n",
            "           *-virtio0 UNCLAIMED\n",
            "                description: Virtual I/O device\n",
            "                physical id: 0\n",
            "                bus info: virtio@0\n",
            "                configuration: driver=virtio_scsi\n",
            "        *-display\n",
            "             description: 3D controller\n",
            "             product: GP104GL [Tesla P4]\n",
            "             vendor: NVIDIA Corporation\n",
            "             physical id: 4\n",
            "             bus info: pci@0000:00:04.0\n",
            "             version: a1\n",
            "             width: 64 bits\n",
            "             clock: 33MHz\n",
            "             capabilities: msi pm bus_master cap_list\n",
            "             configuration: driver=nvidia latency=0\n",
            "             resources: irq:35 memory:fc000000-fcffffff memory:d0000000-dfffffff memory:e0000000-e1ffffff\n",
            "        *-network\n",
            "             description: Ethernet controller\n",
            "             product: Virtio network device\n",
            "             vendor: Red Hat, Inc.\n",
            "             physical id: 5\n",
            "             bus info: pci@0000:00:05.0\n",
            "             version: 00\n",
            "             width: 32 bits\n",
            "             clock: 33MHz\n",
            "             capabilities: msix bus_master cap_list\n",
            "             configuration: driver=virtio-pci latency=0\n",
            "             resources: irq:10 ioport:c040(size=64) memory:fd001000-fd00107f\n",
            "           *-virtio1 UNCLAIMED\n",
            "                description: Virtual I/O device\n",
            "                physical id: 0\n",
            "                bus info: virtio@1\n",
            "                configuration: driver=virtio_net\n",
            "        *-generic:1\n",
            "             description: Unclassified device\n",
            "             product: Virtio RNG\n",
            "             vendor: Red Hat, Inc.\n",
            "             physical id: 6\n",
            "             bus info: pci@0000:00:06.0\n",
            "             version: 00\n",
            "             width: 32 bits\n",
            "             clock: 33MHz\n",
            "             capabilities: msix bus_master cap_list\n",
            "             configuration: driver=virtio-pci latency=0\n",
            "             resources: irq:10 ioport:c080(size=32) memory:fd002000-fd00203f\n",
            "           *-virtio2 UNCLAIMED\n",
            "                description: Virtual I/O device\n",
            "                physical id: 0\n",
            "                bus info: virtio@2\n",
            "                configuration: driver=virtio_rng\n",
            "  *-network\n",
            "       description: Ethernet interface\n",
            "       physical id: 1\n",
            "       logical name: eth0\n",
            "       serial: 02:42:ac:1c:00:02\n",
            "       size: 10Gbit/s\n",
            "       capabilities: ethernet physical\n",
            "       configuration: autonegotiation=off broadcast=yes driver=veth driverversion=1.0 duplex=full ip=172.28.0.2 link=yes multicast=yes port=twisted pair speed=10Gbit/s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1I-Uh2CeEgq",
        "colab_type": "text"
      },
      "source": [
        "# Results\n",
        "GPUがないか、1つのGPUがある場合、30の入力と30の出力をバッチ処理すると、モデルは30を取得し、予想どおり30を出力します。ただし、複数のGPUがある場合は、このような結果を得ることができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oDnvdFJeSOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}