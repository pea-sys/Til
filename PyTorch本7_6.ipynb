{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch本7-6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTXs3j0IduDhe/UkWKiIkR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pea-sys/Til/blob/master/PyTorch%E6%9C%AC7_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7JdF1Elnw07",
        "colab_type": "text"
      },
      "source": [
        "# 7.6 Transformerモデル（分類タスク用）の実装\n",
        "本ファイルでは、クラス分類のTransformerモデルを実装します。\n",
        "※　本章のファイルはすべてUbuntuでの動作を前提としています。Windowsなど文字コードが違う環境での動作にはご注意下さい。\n",
        "\n",
        "# 7.6 学習目標\n",
        "Transformerのモジュール構成を理解する\n",
        "LSTMやRNNを使用せずCNNベースのTransformerで自然言語処理が可能な理由を理解する\n",
        "Transformerを実装できるようになる\n",
        "\n",
        "[写経元](https://github.com/YutaroOgawa/pytorch_advanced/blob/master/7_nlp_sentiment_transformer/7-6_Transformer.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGiInz04oXlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chJPJ7fHoGCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f2f4c48c-ac31-41cf-881e-37358f8604c2"
      },
      "source": [
        "!git clone https://github.com/YutaroOgawa/pytorch_advanced.git\n",
        "%cd pytorch_advanced/\n",
        "%cd 4_pose_estimation"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_advanced'...\n",
            "remote: Enumerating objects: 441, done.\u001b[K\n",
            "Receiving objects:   0% (1/441)   \rReceiving objects:   1% (5/441)   \rReceiving objects:   2% (9/441)   \rReceiving objects:   3% (14/441)   \rReceiving objects:   4% (18/441)   \rReceiving objects:   5% (23/441)   \rReceiving objects:   6% (27/441)   \rReceiving objects:   7% (31/441)   \rReceiving objects:   8% (36/441)   \rReceiving objects:   9% (40/441)   \rReceiving objects:  10% (45/441)   \rReceiving objects:  11% (49/441)   \rReceiving objects:  12% (53/441)   \rReceiving objects:  13% (58/441)   \rReceiving objects:  14% (62/441)   \rReceiving objects:  15% (67/441)   \rReceiving objects:  16% (71/441)   \rReceiving objects:  17% (75/441)   \rReceiving objects:  18% (80/441)   \rReceiving objects:  19% (84/441)   \rReceiving objects:  20% (89/441)   \rReceiving objects:  21% (93/441)   \rReceiving objects:  22% (98/441)   \rReceiving objects:  23% (102/441)   \rReceiving objects:  24% (106/441)   \rReceiving objects:  25% (111/441)   \rReceiving objects:  26% (115/441)   \rReceiving objects:  27% (120/441)   \rReceiving objects:  28% (124/441)   \rReceiving objects:  29% (128/441)   \rReceiving objects:  30% (133/441)   \rReceiving objects:  31% (137/441)   \rReceiving objects:  32% (142/441)   \rReceiving objects:  33% (146/441)   \rReceiving objects:  34% (150/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  35% (155/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  36% (159/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  37% (164/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  38% (168/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  39% (172/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  40% (177/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  41% (181/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  42% (186/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  43% (190/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  44% (195/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  45% (199/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  46% (203/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  47% (208/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  48% (212/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  49% (217/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  50% (221/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  51% (225/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  52% (230/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  53% (234/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  54% (239/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  55% (243/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  56% (247/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  57% (252/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  58% (256/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  59% (261/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  60% (265/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  61% (270/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  62% (274/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  63% (278/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  64% (283/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  65% (287/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  66% (292/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  67% (296/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  68% (300/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  69% (305/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  70% (309/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  71% (314/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  72% (318/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  73% (322/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  74% (327/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  75% (331/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  76% (336/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  77% (340/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  78% (344/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  79% (349/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  80% (353/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  81% (358/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  82% (362/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  83% (367/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  84% (371/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  85% (375/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  86% (380/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  87% (384/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  88% (389/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  89% (393/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  90% (397/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  91% (402/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  92% (406/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  93% (411/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  94% (415/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  95% (419/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  96% (424/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  97% (428/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  98% (433/441), 1.61 MiB | 3.13 MiB/s   \rReceiving objects:  98% (435/441), 1.61 MiB | 3.13 MiB/s   \rremote: Total 441 (delta 0), reused 0 (delta 0), pack-reused 441\u001b[K\n",
            "Receiving objects:  99% (437/441), 11.64 MiB | 11.28 MiB/s   \rReceiving objects: 100% (441/441), 11.64 MiB | 11.28 MiB/s   \rReceiving objects: 100% (441/441), 14.62 MiB | 12.51 MiB/s, done.\n",
            "Resolving deltas:   0% (0/231)   \rResolving deltas:   2% (5/231)   \rResolving deltas:  28% (66/231)   \rResolving deltas:  29% (67/231)   \rResolving deltas:  35% (81/231)   \rResolving deltas:  37% (87/231)   \rResolving deltas:  38% (90/231)   \rResolving deltas:  41% (95/231)   \rResolving deltas:  45% (104/231)   \rResolving deltas:  46% (107/231)   \rResolving deltas:  47% (109/231)   \rResolving deltas:  48% (112/231)   \rResolving deltas:  49% (114/231)   \rResolving deltas:  53% (124/231)   \rResolving deltas:  54% (125/231)   \rResolving deltas:  55% (128/231)   \rResolving deltas:  57% (133/231)   \rResolving deltas:  58% (134/231)   \rResolving deltas:  60% (139/231)   \rResolving deltas:  61% (141/231)   \rResolving deltas:  62% (144/231)   \rResolving deltas:  63% (146/231)   \rResolving deltas:  64% (149/231)   \rResolving deltas:  65% (151/231)   \rResolving deltas:  66% (154/231)   \rResolving deltas:  67% (155/231)   \rResolving deltas:  68% (159/231)   \rResolving deltas:  71% (166/231)   \rResolving deltas:  72% (168/231)   \rResolving deltas:  74% (172/231)   \rResolving deltas:  75% (174/231)   \rResolving deltas:  76% (177/231)   \rResolving deltas:  77% (179/231)   \rResolving deltas:  78% (181/231)   \rResolving deltas:  79% (184/231)   \rResolving deltas:  81% (189/231)   \rResolving deltas:  82% (190/231)   \rResolving deltas:  84% (195/231)   \rResolving deltas:  85% (197/231)   \rResolving deltas:  86% (199/231)   \rResolving deltas:  87% (201/231)   \rResolving deltas:  88% (205/231)   \rResolving deltas:  89% (206/231)   \rResolving deltas:  90% (208/231)   \rResolving deltas:  92% (214/231)   \rResolving deltas:  93% (216/231)   \rResolving deltas:  94% (218/231)   \rResolving deltas:  98% (227/231)   \rResolving deltas:  99% (230/231)   \rResolving deltas: 100% (231/231)   \rResolving deltas: 100% (231/231), done.\n",
            "/content/pytorch_advanced\n",
            "/content/pytorch_advanced/4_pose_estimation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzl6D00tx5rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f1ffbf7-7223-46ec-9ab3-427f3b076e5f"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch_advanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71IGMdAvoUpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# フォルダ「data」が存在しない場合は作成する\n",
        "data_dir = \"data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kUPXn0nza4E",
        "colab_type": "text"
      },
      "source": [
        "# word2vec学習済みモデルをダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-m0De-2zNqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word2vecの日本語学習済みモデル（東北大学 乾・岡崎研究室）をダウンロード。時間が15分ほどかかります\n",
        "\n",
        "url = \"http://www.cl.ecei.tohoku.ac.jp/~m-suzuki/jawiki_vector/data/20170201.tar.bz2\"\n",
        "save_path = \"data/20170201.tar.bz2\"\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcPlvixvzPDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# './data/20170201.tar.bz2'の解凍　5分ほどかかります\n",
        "\n",
        "# tarファイルを読み込み\n",
        "tar = tarfile.open('data/20170201.tar.bz2', 'r|bz2')\n",
        "tar.extractall('data/')  # 解凍\n",
        "tar.close()  # ファイルをクローズ\n",
        "\n",
        "# フォルダ「data」内にフォルダ「entity_vector」というものができ、その中に「entity_vector.model.bin」というファイルができています。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43kVvP5pzeah",
        "colab_type": "text"
      },
      "source": [
        "# fastTextの英語学習済みモデルをダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTGEPVc5ok62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fastTextの公式の英語学習済みモデル（650MB）をダウンロード。時間が5分ほどかかります\n",
        "url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\"\n",
        "save_path = \"data/wiki-news-300d-1M.vec.zip\"\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdM_zlzuooNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# フォルダ「data」内の「/wiki-news-300d-1M.vec.zip」を解凍する\n",
        "\n",
        "zip = zipfile.ZipFile(\"data/wiki-news-300d-1M.vec.zip\")\n",
        "zip.extractall(\"data/\")  # ZIPを解凍\n",
        "zip.close()  # ZIPファイルをクローズ\n",
        "\n",
        "# フォルダ「data」内にフォルダ「wiki-news-300d-1M.vec」というものができます。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrFDrie5zqyx",
        "colab_type": "text"
      },
      "source": [
        "# IMDbデータセットをダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL9J2g1Koqwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMDbデータセットをダウンロード。30秒ほどでダウンロードできます\n",
        "\n",
        "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "save_path = \"data/aclImdb_v1.tar.gz\"\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO_IsZgDosNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# './data/aclImdb_v1.tar.gz'の解凍　1分ほどかかります\n",
        "\n",
        "# tarファイルを読み込み\n",
        "tar = tarfile.open('data/aclImdb_v1.tar.gz')\n",
        "tar.extractall('data/')  # 解凍\n",
        "tar.close()  # ファイルをクローズ\n",
        "\n",
        "# フォルダ「data」内にフォルダ「aclImdb」というものができます。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cqdokmf7y8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tsv形式のファイルにします\n",
        "import glob\n",
        "import os\n",
        "import io\n",
        "import string\n",
        "\n",
        "\n",
        "# 訓練データのtsvファイルを作成します\n",
        "\n",
        "f = open('data/IMDb_train.tsv', 'w')\n",
        "\n",
        "path = 'data/aclImdb/train/pos/'\n",
        "for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "    with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "        text = ff.readline()\n",
        "\n",
        "        # タブがあれば消しておきます\n",
        "        text = text.replace('\\t', \" \")\n",
        "\n",
        "        text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "        f.write(text)\n",
        "\n",
        "path = 'data/aclImdb/train/neg/'\n",
        "for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "    with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "        text = ff.readline()\n",
        "\n",
        "        # タブがあれば消しておきます\n",
        "        text = text.replace('\\t', \" \")\n",
        "\n",
        "        text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "        f.write(text)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1fwnBjo7z3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# テストデータの作成\n",
        "\n",
        "f = open('data/IMDb_test.tsv', 'w')\n",
        "\n",
        "path = 'data/aclImdb/test/pos/'\n",
        "for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "    with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "        text = ff.readline()\n",
        "\n",
        "        # タブがあれば消しておきます\n",
        "        text = text.replace('\\t', \" \")\n",
        "\n",
        "        text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "        f.write(text)\n",
        "\n",
        "\n",
        "path = 'data/aclImdb/test/neg/'\n",
        "\n",
        "for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "    with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "        text = ff.readline()\n",
        "\n",
        "        # タブがあれば消しておきます\n",
        "        text = text.replace('\\t', \" \")\n",
        "\n",
        "        text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "        f.write(text)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myc_IfKv74ME",
        "colab_type": "text"
      },
      "source": [
        "# 2. 前処理と単語分割の関数を定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziyXplBK77Kv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bccc31eb-b152-41cd-ab0f-ede3a9121562"
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "# 以下の記号はスペースに置き換えます（カンマ、ピリオドを除く）。\n",
        "# punctuationとは日本語で句点という意味です\n",
        "print(\"区切り文字：\", string.punctuation)\n",
        "# !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "# 前処理\n",
        "\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    # 改行コードを消去\n",
        "    text = re.sub('<br />', '', text)\n",
        "\n",
        "    # カンマ、ピリオド以外の記号をスペースに置換\n",
        "    for p in string.punctuation:\n",
        "        if (p == \".\") or (p == \",\"):\n",
        "            continue\n",
        "        else:\n",
        "            text = text.replace(p, \" \")\n",
        "\n",
        "    # ピリオドなどの前後にはスペースを入れておく\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    return text\n",
        "\n",
        "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
        "\n",
        "\n",
        "def tokenizer_punctuation(text):\n",
        "    return text.strip().split()\n",
        "\n",
        "\n",
        "# 前処理と分かち書きをまとめた関数を定義\n",
        "def tokenizer_with_preprocessing(text):\n",
        "    text = preprocessing_text(text)\n",
        "    ret = tokenizer_punctuation(text)\n",
        "    return ret\n",
        "\n",
        "\n",
        "# 動作を確認します\n",
        "print(tokenizer_with_preprocessing('I like cats.'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "区切り文字： !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "['I', 'like', 'cats', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK8b6ZqV7-r2",
        "colab_type": "text"
      },
      "source": [
        "# DataLoaderの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVCRK46y78IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
        "import torchtext\n",
        "\n",
        "\n",
        "# 文章とラベルの両方に用意します\n",
        "max_length = 256\n",
        "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"<cls>\", eos_token=\"<eos>\")\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# 引数の意味は次の通り\n",
        "# init_token：全部の文章で、文頭に入れておく単語\n",
        "# eos_token：全部の文章で、文末に入れておく単語"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EJV5kre8CVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# フォルダ「data」から各tsvファイルを読み込みます\n",
        "train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path='data/', train='IMDb_train.tsv',\n",
        "    test='IMDb_test.tsv', format='tsv',\n",
        "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n",
        "import random\n",
        "# torchtext.data.Datasetのsplit関数で訓練データとvalidationデータを分ける\n",
        "\n",
        "train_ds, val_ds = train_val_ds.split(\n",
        "    split_ratio=0.8, random_state=random.seed(1234))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8sDhS4t8L9n",
        "colab_type": "text"
      },
      "source": [
        "# ボキャブラリーを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5ghzGvI8J5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0efd1901-18ec-436d-8cb4-1e7763499836"
      },
      "source": [
        "\n",
        "# torchtextで単語ベクトルとして英語学習済みモデルを読み込みます\n",
        "\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "english_fasttext_vectors = Vectors(name='data/wiki-news-300d-1M.vec')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/999994 [00:00<?, ?it/s]Skipping token b'999994' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|█████████▉| 998944/999994 [01:31<00:00, 11025.57it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oypt4vg7xrGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ベクトル化したバージョンのボキャブラリーを作成します\n",
        "TEXT.build_vocab(train_ds, vectors=english_fasttext_vectors, min_freq=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvur6NW8Mra3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
        "train_dl = torchtext.data.Iterator(train_ds, batch_size=24, train=True)\n",
        "\n",
        "val_dl = torchtext.data.Iterator(\n",
        "    val_ds, batch_size=24, train=False, sort=False)\n",
        "\n",
        "test_dl = torchtext.data.Iterator(\n",
        "    test_ds, batch_size=24, train=False, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k267tbNUOfa1",
        "colab_type": "text"
      },
      "source": [
        "# 新節"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rANY8cgiPOps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torchtext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbfgYzx4PRHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup seeds\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuLoZXkePTuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Embedder(nn.Module):\n",
        "    '''idで示されている単語をベクトルに変換します'''\n",
        "\n",
        "    def __init__(self, text_embedding_vectors):\n",
        "        super(Embedder, self).__init__()\n",
        "\n",
        "        self.embeddings = nn.Embedding.from_pretrained(\n",
        "            embeddings=text_embedding_vectors, freeze=True)\n",
        "        # freeze=Trueによりバックプロパゲーションで更新されず変化しなくなります\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_vec = self.embeddings(x)\n",
        "\n",
        "        return x_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H29fg-HOa6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "56b02029-962e-48aa-8fc5-e3e4fa408a92"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# 前節のDataLoaderなどを取得\n",
        "#from utils.dataloader import get_IMDb_DataLoaders_and_TEXT\n",
        "#train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(\n",
        "#    max_length=256, batch_size=24)\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(train_dl))\n",
        "\n",
        "# モデル構築\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 単語をベクトルに\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x.shape)\n",
        "print(\"出力のテンソルサイズ：\", x1.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "入力のテンソルサイズ： torch.Size([24, 256])\n",
            "出力のテンソルサイズ： torch.Size([24, 256, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV6peX6gPH7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
        "\n",
        "    def __init__(self, d_model=300, max_seq_len=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model  # 単語ベクトルの次元数\n",
        "\n",
        "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        # GPUが使える場合はGPUへ送る、ここでは省略。実際に学習時には使用する\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # pe = pe.to(device)\n",
        "\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos /\n",
        "                                          (10000 ** ((2 * (i + 1))/d_model)))\n",
        "\n",
        "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "        # 勾配を計算しないようにする\n",
        "        self.pe.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # 入力xとPositonal Encodingを足し算する\n",
        "        # xがpeよりも小さいので、大きくする\n",
        "        ret = math.sqrt(self.d_model)*x + self.pe\n",
        "        return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpjFOL4kPXtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a5a0f571-fe0a-43cc-a011-2c986ff88be9"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# モデル構築\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 単語をベクトルに\n",
        "x2 = net2(x1)\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x1.shape)\n",
        "print(\"出力のテンソルサイズ：\", x2.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "入力のテンソルサイズ： torch.Size([24, 256, 300])\n",
            "出力のテンソルサイズ： torch.Size([24, 256, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5hOlfeGPdvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    '''Transformerは本当はマルチヘッドAttentionですが、\n",
        "    分かりやすさを優先しシングルAttentionで実装します'''\n",
        "\n",
        "    def __init__(self, d_model=300):\n",
        "        super().__init__()\n",
        "\n",
        "        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # 出力時に使用する全結合層\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Attentionの大きさ調整の変数\n",
        "        self.d_k = d_model\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        # 全結合層で特徴量を変換\n",
        "        k = self.k_linear(k)\n",
        "        q = self.q_linear(q)\n",
        "        v = self.v_linear(v)\n",
        "\n",
        "        # Attentionの値を計算する\n",
        "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
        "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # ここでmaskを計算\n",
        "        mask = mask.unsqueeze(1)\n",
        "        weights = weights.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # softmaxで規格化をする\n",
        "        normlized_weights = F.softmax(weights, dim=-1)\n",
        "\n",
        "        # AttentionをValueとかけ算\n",
        "        output = torch.matmul(normlized_weights, v)\n",
        "\n",
        "        # 全結合層で特徴量を変換\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, normlized_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwrPJRT2PgrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
        "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.dropout(F.relu(x))\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzXQJXUsPjnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # LayerNormalization層\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Attention層\n",
        "        self.attn = Attention(d_model)\n",
        "\n",
        "        # Attentionのあとの全結合層2つ\n",
        "        self.ff = FeedForward(d_model)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # 正規化とAttention\n",
        "        x_normlized = self.norm_1(x)\n",
        "        output, normlized_weights = self.attn(\n",
        "            x_normlized, x_normlized, x_normlized, mask)\n",
        "        \n",
        "        x2 = x + self.dropout_1(output)\n",
        "\n",
        "        # 正規化と全結合層\n",
        "        x_normlized2 = self.norm_2(x2)\n",
        "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
        "\n",
        "        return output, normlized_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEIy6kkxPlp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "75855c06-77ff-4fbf-8d02-5582899d54b5"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# モデル構築\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "net3 = TransformerBlock(d_model=300)\n",
        "\n",
        "# maskの作成\n",
        "x = batch.Text[0]\n",
        "input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
        "input_mask = (x != input_pad)\n",
        "print(input_mask[0])\n",
        "\n",
        "# 入出力\n",
        "x1 = net1(x)  # 単語をベクトルに\n",
        "x2 = net2(x1)  # Positon情報を足し算\n",
        "x3, normlized_weights = net3(x2, input_mask)  # Self-Attentionで特徴量を変換\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x2.shape)\n",
        "print(\"出力のテンソルサイズ：\", x3.shape)\n",
        "print(\"Attentionのサイズ：\", normlized_weights.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True])\n",
            "入力のテンソルサイズ： torch.Size([24, 256, 300])\n",
            "出力のテンソルサイズ： torch.Size([24, 256, 300])\n",
            "Attentionのサイズ： torch.Size([24, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Iks8GPbPnYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
        "\n",
        "    def __init__(self, d_model=300, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # 全結合層\n",
        "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
        "\n",
        "        # 重み初期化処理\n",
        "        nn.init.normal_(self.linear.weight, std=0.02)\n",
        "        nn.init.normal_(self.linear.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
        "        out = self.linear(x0)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhV0Gi5-PpXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "78b89efd-5c52-4fe1-80a1-70ef2999b0dd"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(train_dl))\n",
        "\n",
        "# モデル構築\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "net3 = TransformerBlock(d_model=300)\n",
        "net4 = ClassificationHead(output_dim=2, d_model=300)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 単語をベクトルに\n",
        "x2 = net2(x1)  # Positon情報を足し算\n",
        "x3, normlized_weights = net3(x2, input_mask)  # Self-Attentionで特徴量を変換\n",
        "x4 = net4(x3)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x3.shape)\n",
        "print(\"出力のテンソルサイズ：\", x4.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "入力のテンソルサイズ： torch.Size([24, 256, 300])\n",
            "出力のテンソルサイズ： torch.Size([24, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM7fDKbPPrSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 最終的なTransformerモデルのクラス\n",
        "\n",
        "\n",
        "class TransformerClassification(nn.Module):\n",
        "    '''Transformerでクラス分類させる'''\n",
        "\n",
        "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # モデル構築\n",
        "        self.net1 = Embedder(text_embedding_vectors)\n",
        "        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
        "        self.net3_1 = TransformerBlock(d_model=d_model)\n",
        "        self.net3_2 = TransformerBlock(d_model=d_model)\n",
        "        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x1 = self.net1(x)  # 単語をベクトルに\n",
        "        x2 = self.net2(x1)  # Positon情報を足し算\n",
        "        x3_1, normlized_weights_1 = self.net3_1(\n",
        "            x2, mask)  # Self-Attentionで特徴量を変換\n",
        "        x3_2, normlized_weights_2 = self.net3_2(\n",
        "            x3_1, mask)  # Self-Attentionで特徴量を変換\n",
        "        x4 = self.net4(x3_2)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
        "        return x4, normlized_weights_1, normlized_weights_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXEZIzK0PteW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "dd4d6a80-dda9-4772-8ca1-189c1abf230b"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(train_dl))\n",
        "\n",
        "# モデル構築\n",
        "net = TransformerClassification(\n",
        "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "input_mask = (x != input_pad)\n",
        "out, normlized_weights_1, normlized_weights_2 = net(x, input_mask)\n",
        "\n",
        "print(\"出力のテンソルサイズ：\", out.shape)\n",
        "print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "出力のテンソルサイズ： torch.Size([24, 2])\n",
            "出力テンソルのsigmoid： tensor([[0.6892, 0.3108],\n",
            "        [0.7205, 0.2795],\n",
            "        [0.7271, 0.2729],\n",
            "        [0.7012, 0.2988],\n",
            "        [0.7002, 0.2998],\n",
            "        [0.6985, 0.3015],\n",
            "        [0.6748, 0.3252],\n",
            "        [0.6424, 0.3576],\n",
            "        [0.7157, 0.2843],\n",
            "        [0.7197, 0.2803],\n",
            "        [0.7241, 0.2759],\n",
            "        [0.7038, 0.2962],\n",
            "        [0.6818, 0.3182],\n",
            "        [0.7047, 0.2953],\n",
            "        [0.7229, 0.2771],\n",
            "        [0.6889, 0.3111],\n",
            "        [0.6946, 0.3054],\n",
            "        [0.6894, 0.3106],\n",
            "        [0.6953, 0.3047],\n",
            "        [0.7126, 0.2874],\n",
            "        [0.7142, 0.2858],\n",
            "        [0.7314, 0.2686],\n",
            "        [0.6654, 0.3346],\n",
            "        [0.7328, 0.2672]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRf182PjPvM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}